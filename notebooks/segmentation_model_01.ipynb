{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ../../geoai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84684855",
   "metadata": {},
   "source": [
    "### Reload Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c623d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'geoai.utils' from 'C:\\\\Users\\\\GRSS NATAWARA\\\\Documents\\\\TA Remote Sensing\\\\geoai\\\\geoai\\\\utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geoai\n",
    "import geoai.label_utils\n",
    "import geoai.utils\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import importlib\n",
    "importlib.reload(geoai)\n",
    "importlib.reload(geoai.label_utils)\n",
    "importlib.reload(geoai.utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e252c",
   "metadata": {},
   "source": [
    "## Train single image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51114b2",
   "metadata": {},
   "source": [
    "### Build dataset [stride 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066c1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_path = \"../data/raw/images/S2H_2023_2023_07_30_nodata.tif\"\n",
    "label_path = \"../data/raw/cdl/2023_30m_cdls_10m_remap.tif\"\n",
    "\n",
    "out_name = \"crop_mapping_2023_07_30\"\n",
    "data_folder = f\"../data/processed/{out_name}\"\n",
    "\n",
    "model_folder = f\"../models/{out_name}\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# this function will create folders (annotations, images, labels)\n",
    "# tiles = geoai.export_geotiff_tiles(\n",
    "#     in_raster=image_path,\n",
    "#     out_folder=data_folder,\n",
    "#     in_class_data=label_path,\n",
    "#     tile_size=256,\n",
    "#     stride=64,\n",
    "#     buffer_radius=0,\n",
    "#     skip_empty_tiles=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76dade",
   "metadata": {},
   "source": [
    "### Train DeepLabV3+ [oversampling]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32560d6",
   "metadata": {},
   "source": [
    "#### Setup loss criterios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7964bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from geoai import losses\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "criterion = losses.DECBLoss(\n",
    "    num_classes=11,\n",
    "    beta=0.9999,          # smoothing factor (as in paper)\n",
    "    loss_type=\"ce\",       # or \"focal\"\n",
    "    gamma=2.0,            # focal gamma\n",
    "    ignore_index=255,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f778e71",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85787be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 9112 image files and 9112 label files\n",
      "Training on 7289 images, validating on 1823 images\n",
      "Checking image sizes for compatibility...\n",
      "All sampled images have the same size: (256, 256)\n",
      "No resizing needed.\n",
      "Building class-balanced sampler (strategy='presence') ...\n",
      "Class-balanced sampler ready. Non-empty classes: 11/11.\n",
      "Using class balanced sampler\n",
      "Testing data loader...\n",
      "Data loader test passed.\n",
      "Starting training with deeplabv3plus + efficientnet-b5\n",
      "Model parameters: 29,497,579\n",
      "Epoch: 1, Batch: 1/911, Loss: 2.4053, Time: 0.98s\n",
      "Epoch: 1, Batch: 11/911, Loss: 2.1751, Time: 3.70s\n",
      "Epoch: 1, Batch: 21/911, Loss: 1.6029, Time: 3.61s\n",
      "Epoch: 1, Batch: 31/911, Loss: 1.5354, Time: 3.62s\n",
      "Epoch: 1, Batch: 41/911, Loss: 1.5763, Time: 3.65s\n",
      "Epoch: 1, Batch: 51/911, Loss: 0.9991, Time: 3.60s\n",
      "Epoch: 1, Batch: 61/911, Loss: 1.1627, Time: 3.54s\n",
      "Epoch: 1, Batch: 71/911, Loss: 1.4692, Time: 3.54s\n",
      "Epoch: 1, Batch: 81/911, Loss: 1.9119, Time: 3.54s\n",
      "Epoch: 1, Batch: 91/911, Loss: 1.4102, Time: 3.59s\n",
      "Epoch: 1, Batch: 101/911, Loss: 1.0509, Time: 3.66s\n",
      "Epoch: 1, Batch: 111/911, Loss: 1.3061, Time: 3.54s\n",
      "Epoch: 1, Batch: 121/911, Loss: 0.9671, Time: 3.54s\n",
      "Epoch: 1, Batch: 131/911, Loss: 1.3664, Time: 3.51s\n",
      "Epoch: 1, Batch: 141/911, Loss: 1.4421, Time: 3.53s\n",
      "Epoch: 1, Batch: 151/911, Loss: 1.3670, Time: 3.44s\n",
      "Epoch: 1, Batch: 161/911, Loss: 1.5521, Time: 3.37s\n",
      "Epoch: 1, Batch: 171/911, Loss: 1.0743, Time: 3.41s\n",
      "Epoch: 1, Batch: 181/911, Loss: 1.2512, Time: 3.50s\n",
      "Epoch: 1, Batch: 191/911, Loss: 1.6189, Time: 3.49s\n",
      "Epoch: 1, Batch: 201/911, Loss: 1.1320, Time: 3.49s\n",
      "Epoch: 1, Batch: 211/911, Loss: 1.3215, Time: 3.48s\n",
      "Epoch: 1, Batch: 221/911, Loss: 1.4659, Time: 3.50s\n",
      "Epoch: 1, Batch: 231/911, Loss: 1.2490, Time: 3.39s\n",
      "Epoch: 1, Batch: 241/911, Loss: 1.2444, Time: 3.35s\n",
      "Epoch: 1, Batch: 251/911, Loss: 1.6925, Time: 3.40s\n",
      "Epoch: 1, Batch: 261/911, Loss: 1.5121, Time: 3.32s\n",
      "Epoch: 1, Batch: 271/911, Loss: 1.3442, Time: 3.41s\n",
      "Epoch: 1, Batch: 281/911, Loss: 0.9880, Time: 3.52s\n",
      "Epoch: 1, Batch: 291/911, Loss: 1.1755, Time: 3.50s\n",
      "Epoch: 1, Batch: 301/911, Loss: 1.0043, Time: 3.49s\n",
      "Epoch: 1, Batch: 311/911, Loss: 1.5778, Time: 3.53s\n",
      "Epoch: 1, Batch: 321/911, Loss: 1.3920, Time: 3.46s\n",
      "Epoch: 1, Batch: 331/911, Loss: 1.1181, Time: 3.35s\n",
      "Epoch: 1, Batch: 341/911, Loss: 1.2149, Time: 3.28s\n",
      "Epoch: 1, Batch: 351/911, Loss: 1.1589, Time: 3.25s\n",
      "Epoch: 1, Batch: 361/911, Loss: 1.2324, Time: 3.36s\n",
      "Epoch: 1, Batch: 371/911, Loss: 1.5037, Time: 3.41s\n",
      "Epoch: 1, Batch: 381/911, Loss: 1.2170, Time: 3.40s\n",
      "Epoch: 1, Batch: 391/911, Loss: 1.2517, Time: 3.38s\n",
      "Epoch: 1, Batch: 401/911, Loss: 1.1529, Time: 3.37s\n",
      "Epoch: 1, Batch: 411/911, Loss: 1.1517, Time: 3.41s\n",
      "Epoch: 1, Batch: 421/911, Loss: 0.8324, Time: 3.37s\n",
      "Epoch: 1, Batch: 431/911, Loss: 1.3616, Time: 3.28s\n",
      "Epoch: 1, Batch: 441/911, Loss: 1.4777, Time: 3.30s\n",
      "Epoch: 1, Batch: 451/911, Loss: 1.1047, Time: 3.36s\n",
      "Epoch: 1, Batch: 461/911, Loss: 1.2754, Time: 3.37s\n",
      "Epoch: 1, Batch: 471/911, Loss: 1.2226, Time: 3.38s\n",
      "Epoch: 1, Batch: 481/911, Loss: 0.7715, Time: 3.26s\n",
      "Epoch: 1, Batch: 491/911, Loss: 1.0848, Time: 3.37s\n",
      "Epoch: 1, Batch: 501/911, Loss: 1.2572, Time: 3.41s\n",
      "Epoch: 1, Batch: 511/911, Loss: 1.0468, Time: 3.40s\n",
      "Epoch: 1, Batch: 521/911, Loss: 1.3659, Time: 3.25s\n",
      "Epoch: 1, Batch: 531/911, Loss: 1.4175, Time: 3.37s\n",
      "Epoch: 1, Batch: 541/911, Loss: 0.9403, Time: 3.29s\n",
      "Epoch: 1, Batch: 551/911, Loss: 1.1125, Time: 3.32s\n",
      "Epoch: 1, Batch: 561/911, Loss: 0.8584, Time: 3.31s\n",
      "Epoch: 1, Batch: 571/911, Loss: 1.2487, Time: 3.36s\n",
      "Epoch: 1, Batch: 581/911, Loss: 1.0081, Time: 3.36s\n",
      "Epoch: 1, Batch: 591/911, Loss: 1.4933, Time: 3.41s\n",
      "Epoch: 1, Batch: 601/911, Loss: 1.0098, Time: 3.30s\n",
      "Epoch: 1, Batch: 611/911, Loss: 1.2694, Time: 3.28s\n",
      "Epoch: 1, Batch: 621/911, Loss: 1.1484, Time: 3.26s\n",
      "Epoch: 1, Batch: 631/911, Loss: 0.8106, Time: 3.17s\n",
      "Epoch: 1, Batch: 641/911, Loss: 0.9688, Time: 3.18s\n",
      "Epoch: 1, Batch: 651/911, Loss: 0.8173, Time: 3.15s\n",
      "Epoch: 1, Batch: 661/911, Loss: 1.3514, Time: 3.18s\n",
      "Epoch: 1, Batch: 671/911, Loss: 0.9417, Time: 3.24s\n",
      "Epoch: 1, Batch: 681/911, Loss: 1.2814, Time: 3.25s\n",
      "Epoch: 1, Batch: 691/911, Loss: 1.0814, Time: 3.30s\n",
      "Epoch: 1, Batch: 701/911, Loss: 1.0363, Time: 3.24s\n",
      "Epoch: 1, Batch: 711/911, Loss: 0.9464, Time: 3.26s\n",
      "Epoch: 1, Batch: 721/911, Loss: 1.0209, Time: 3.28s\n",
      "Epoch: 1, Batch: 731/911, Loss: 1.0442, Time: 3.23s\n",
      "Epoch: 1, Batch: 741/911, Loss: 0.9860, Time: 3.32s\n",
      "Epoch: 1, Batch: 751/911, Loss: 1.2540, Time: 3.32s\n",
      "Epoch: 1, Batch: 761/911, Loss: 1.0061, Time: 3.32s\n",
      "Epoch: 1, Batch: 771/911, Loss: 1.0333, Time: 3.30s\n",
      "Epoch: 1, Batch: 781/911, Loss: 1.2233, Time: 3.28s\n",
      "Epoch: 1, Batch: 791/911, Loss: 0.9172, Time: 3.46s\n",
      "Epoch: 1, Batch: 801/911, Loss: 1.2555, Time: 3.26s\n",
      "Epoch: 1, Batch: 811/911, Loss: 1.2924, Time: 3.31s\n",
      "Epoch: 1, Batch: 821/911, Loss: 1.3189, Time: 3.20s\n",
      "Epoch: 1, Batch: 831/911, Loss: 1.2445, Time: 3.28s\n",
      "Epoch: 1, Batch: 841/911, Loss: 0.9688, Time: 3.19s\n",
      "Epoch: 1, Batch: 851/911, Loss: 1.1127, Time: 3.36s\n",
      "Epoch: 1, Batch: 861/911, Loss: 1.0387, Time: 3.44s\n",
      "Epoch: 1, Batch: 871/911, Loss: 1.3073, Time: 3.28s\n",
      "Epoch: 1, Batch: 881/911, Loss: 0.8191, Time: 3.31s\n",
      "Epoch: 1, Batch: 891/911, Loss: 1.4960, Time: 3.26s\n",
      "Epoch: 1, Batch: 901/911, Loss: 0.9675, Time: 3.29s\n",
      "Epoch: 1, Batch: 911/911, Loss: 0.6919, Time: 3.27s\n",
      "Epoch 1/100: Train Loss: 1.2227, Val Loss: 1.3647, Val IoU: 0.1362, Val Dice: 0.1825\n",
      "Saving best model with IoU: 0.1362\n",
      "Epoch: 2, Batch: 1/911, Loss: 0.8678, Time: 0.43s\n",
      "Epoch: 2, Batch: 11/911, Loss: 0.9553, Time: 3.30s\n",
      "Epoch: 2, Batch: 21/911, Loss: 1.2476, Time: 3.32s\n",
      "Epoch: 2, Batch: 31/911, Loss: 1.1505, Time: 3.28s\n",
      "Epoch: 2, Batch: 41/911, Loss: 1.0788, Time: 3.43s\n",
      "Epoch: 2, Batch: 51/911, Loss: 1.2104, Time: 3.31s\n",
      "Epoch: 2, Batch: 61/911, Loss: 1.3629, Time: 3.25s\n",
      "Epoch: 2, Batch: 71/911, Loss: 1.1196, Time: 3.27s\n",
      "Epoch: 2, Batch: 81/911, Loss: 1.2418, Time: 3.24s\n",
      "Epoch: 2, Batch: 91/911, Loss: 1.1288, Time: 3.19s\n",
      "Epoch: 2, Batch: 101/911, Loss: 1.2678, Time: 3.15s\n",
      "Epoch: 2, Batch: 111/911, Loss: 0.9857, Time: 3.14s\n",
      "Epoch: 2, Batch: 121/911, Loss: 1.2936, Time: 3.11s\n",
      "Epoch: 2, Batch: 131/911, Loss: 1.3490, Time: 3.13s\n",
      "Epoch: 2, Batch: 141/911, Loss: 0.9145, Time: 3.20s\n",
      "Epoch: 2, Batch: 151/911, Loss: 0.8003, Time: 3.31s\n",
      "Epoch: 2, Batch: 161/911, Loss: 0.9852, Time: 3.32s\n",
      "Epoch: 2, Batch: 171/911, Loss: 1.0721, Time: 3.24s\n",
      "Epoch: 2, Batch: 181/911, Loss: 0.9438, Time: 3.30s\n",
      "Epoch: 2, Batch: 191/911, Loss: 0.7995, Time: 3.20s\n",
      "Epoch: 2, Batch: 201/911, Loss: 1.0982, Time: 3.12s\n",
      "Epoch: 2, Batch: 211/911, Loss: 0.9974, Time: 3.10s\n",
      "Epoch: 2, Batch: 221/911, Loss: 1.1798, Time: 3.11s\n",
      "Epoch: 2, Batch: 231/911, Loss: 1.0736, Time: 3.04s\n",
      "Epoch: 2, Batch: 241/911, Loss: 1.1577, Time: 3.07s\n",
      "Epoch: 2, Batch: 251/911, Loss: 1.2166, Time: 3.11s\n",
      "Epoch: 2, Batch: 261/911, Loss: 1.1285, Time: 3.15s\n",
      "Epoch: 2, Batch: 271/911, Loss: 0.9548, Time: 3.23s\n",
      "Epoch: 2, Batch: 281/911, Loss: 0.8540, Time: 3.22s\n",
      "Epoch: 2, Batch: 291/911, Loss: 1.0147, Time: 3.32s\n",
      "Epoch: 2, Batch: 301/911, Loss: 0.9741, Time: 3.14s\n",
      "Epoch: 2, Batch: 311/911, Loss: 1.0251, Time: 3.06s\n",
      "Epoch: 2, Batch: 321/911, Loss: 1.1463, Time: 3.07s\n",
      "Epoch: 2, Batch: 331/911, Loss: 1.1747, Time: 3.09s\n",
      "Epoch: 2, Batch: 341/911, Loss: 1.0630, Time: 3.05s\n",
      "Epoch: 2, Batch: 351/911, Loss: 1.3599, Time: 3.09s\n",
      "Epoch: 2, Batch: 361/911, Loss: 0.9101, Time: 3.09s\n",
      "Epoch: 2, Batch: 371/911, Loss: 1.0834, Time: 3.13s\n",
      "Epoch: 2, Batch: 381/911, Loss: 1.2004, Time: 3.18s\n",
      "Epoch: 2, Batch: 391/911, Loss: 0.9512, Time: 3.22s\n",
      "Epoch: 2, Batch: 401/911, Loss: 0.8246, Time: 3.21s\n",
      "Epoch: 2, Batch: 411/911, Loss: 1.0244, Time: 3.05s\n",
      "Epoch: 2, Batch: 421/911, Loss: 0.7527, Time: 3.07s\n",
      "Epoch: 2, Batch: 431/911, Loss: 0.9657, Time: 3.08s\n",
      "Epoch: 2, Batch: 441/911, Loss: 1.1879, Time: 3.09s\n",
      "Epoch: 2, Batch: 451/911, Loss: 0.9792, Time: 3.07s\n",
      "Epoch: 2, Batch: 461/911, Loss: 0.8825, Time: 3.19s\n",
      "Epoch: 2, Batch: 471/911, Loss: 0.8295, Time: 3.17s\n",
      "Epoch: 2, Batch: 481/911, Loss: 0.7415, Time: 3.22s\n",
      "Epoch: 2, Batch: 491/911, Loss: 0.9417, Time: 3.13s\n",
      "Epoch: 2, Batch: 501/911, Loss: 0.9495, Time: 3.14s\n",
      "Epoch: 2, Batch: 511/911, Loss: 0.8855, Time: 3.07s\n",
      "Epoch: 2, Batch: 521/911, Loss: 1.0145, Time: 3.05s\n",
      "Epoch: 2, Batch: 531/911, Loss: 0.7609, Time: 3.01s\n",
      "Epoch: 2, Batch: 541/911, Loss: 1.2292, Time: 2.99s\n",
      "Epoch: 2, Batch: 551/911, Loss: 0.9102, Time: 3.05s\n",
      "Epoch: 2, Batch: 561/911, Loss: 1.1853, Time: 3.06s\n",
      "Epoch: 2, Batch: 571/911, Loss: 1.0670, Time: 3.04s\n",
      "Epoch: 2, Batch: 581/911, Loss: 1.0342, Time: 3.01s\n",
      "Epoch: 2, Batch: 591/911, Loss: 0.9577, Time: 3.02s\n",
      "Epoch: 2, Batch: 601/911, Loss: 1.3455, Time: 3.04s\n",
      "Epoch: 2, Batch: 611/911, Loss: 0.8840, Time: 3.02s\n",
      "Epoch: 2, Batch: 621/911, Loss: 0.8521, Time: 3.06s\n",
      "Epoch: 2, Batch: 631/911, Loss: 1.6491, Time: 3.04s\n",
      "Epoch: 2, Batch: 641/911, Loss: 1.0040, Time: 3.02s\n",
      "Epoch: 2, Batch: 651/911, Loss: 0.6598, Time: 3.06s\n",
      "Epoch: 2, Batch: 661/911, Loss: 0.9387, Time: 3.01s\n",
      "Epoch: 2, Batch: 671/911, Loss: 0.8581, Time: 3.11s\n",
      "Epoch: 2, Batch: 681/911, Loss: 0.6670, Time: 3.20s\n",
      "Epoch: 2, Batch: 691/911, Loss: 0.8246, Time: 3.20s\n",
      "Epoch: 2, Batch: 701/911, Loss: 1.2919, Time: 3.08s\n",
      "Epoch: 2, Batch: 711/911, Loss: 1.1685, Time: 3.18s\n",
      "Epoch: 2, Batch: 721/911, Loss: 0.6809, Time: 3.20s\n",
      "Epoch: 2, Batch: 731/911, Loss: 1.1382, Time: 3.20s\n",
      "Epoch: 2, Batch: 741/911, Loss: 0.8962, Time: 3.11s\n",
      "Epoch: 2, Batch: 751/911, Loss: 0.6480, Time: 3.20s\n",
      "Epoch: 2, Batch: 761/911, Loss: 1.0300, Time: 3.22s\n",
      "Epoch: 2, Batch: 771/911, Loss: 1.0359, Time: 3.20s\n",
      "Epoch: 2, Batch: 781/911, Loss: 1.3916, Time: 3.15s\n",
      "Epoch: 2, Batch: 791/911, Loss: 0.8031, Time: 3.18s\n",
      "Epoch: 2, Batch: 801/911, Loss: 0.8693, Time: 3.21s\n",
      "Epoch: 2, Batch: 811/911, Loss: 0.9335, Time: 3.17s\n",
      "Epoch: 2, Batch: 821/911, Loss: 1.3048, Time: 3.14s\n",
      "Epoch: 2, Batch: 831/911, Loss: 0.8627, Time: 3.16s\n",
      "Epoch: 2, Batch: 841/911, Loss: 0.9166, Time: 3.17s\n",
      "Epoch: 2, Batch: 851/911, Loss: 0.7840, Time: 3.11s\n",
      "Epoch: 2, Batch: 861/911, Loss: 1.0372, Time: 3.03s\n",
      "Epoch: 2, Batch: 871/911, Loss: 0.9296, Time: 3.01s\n",
      "Epoch: 2, Batch: 881/911, Loss: 0.8431, Time: 3.01s\n",
      "Epoch: 2, Batch: 891/911, Loss: 0.6935, Time: 3.04s\n",
      "Epoch: 2, Batch: 901/911, Loss: 1.1239, Time: 3.02s\n",
      "Epoch: 2, Batch: 911/911, Loss: 0.8729, Time: 3.05s\n",
      "Epoch 2/100: Train Loss: 1.0181, Val Loss: 1.0100, Val IoU: 0.1969, Val Dice: 0.2458\n",
      "Saving best model with IoU: 0.1969\n",
      "Epoch: 3, Batch: 1/911, Loss: 1.0700, Time: 0.35s\n",
      "Epoch: 3, Batch: 11/911, Loss: 0.8187, Time: 3.04s\n",
      "Epoch: 3, Batch: 21/911, Loss: 0.9244, Time: 3.01s\n",
      "Epoch: 3, Batch: 31/911, Loss: 0.9825, Time: 2.97s\n",
      "Epoch: 3, Batch: 41/911, Loss: 0.7497, Time: 3.02s\n",
      "Epoch: 3, Batch: 51/911, Loss: 0.9776, Time: 3.02s\n",
      "Epoch: 3, Batch: 61/911, Loss: 1.1519, Time: 3.11s\n",
      "Epoch: 3, Batch: 71/911, Loss: 1.2584, Time: 2.99s\n",
      "Epoch: 3, Batch: 81/911, Loss: 0.9411, Time: 3.02s\n",
      "Epoch: 3, Batch: 91/911, Loss: 0.8688, Time: 3.04s\n",
      "Epoch: 3, Batch: 101/911, Loss: 0.9914, Time: 3.00s\n",
      "Epoch: 3, Batch: 111/911, Loss: 1.0642, Time: 3.03s\n",
      "Epoch: 3, Batch: 121/911, Loss: 1.2003, Time: 2.98s\n",
      "Epoch: 3, Batch: 131/911, Loss: 0.9621, Time: 2.97s\n",
      "Epoch: 3, Batch: 141/911, Loss: 1.0759, Time: 3.02s\n",
      "Epoch: 3, Batch: 151/911, Loss: 0.9429, Time: 3.12s\n",
      "Epoch: 3, Batch: 161/911, Loss: 1.1030, Time: 3.11s\n",
      "Epoch: 3, Batch: 171/911, Loss: 0.8811, Time: 3.15s\n",
      "Epoch: 3, Batch: 181/911, Loss: 0.8713, Time: 3.09s\n",
      "Epoch: 3, Batch: 191/911, Loss: 1.0381, Time: 3.07s\n",
      "Epoch: 3, Batch: 201/911, Loss: 0.9013, Time: 3.01s\n",
      "Epoch: 3, Batch: 211/911, Loss: 0.8842, Time: 3.14s\n",
      "Epoch: 3, Batch: 221/911, Loss: 0.8436, Time: 3.03s\n",
      "Epoch: 3, Batch: 231/911, Loss: 0.8687, Time: 3.02s\n",
      "Epoch: 3, Batch: 241/911, Loss: 0.7312, Time: 3.03s\n",
      "Epoch: 3, Batch: 251/911, Loss: 0.7863, Time: 3.00s\n",
      "Epoch: 3, Batch: 261/911, Loss: 0.9283, Time: 2.98s\n",
      "Epoch: 3, Batch: 271/911, Loss: 1.2622, Time: 3.01s\n",
      "Epoch: 3, Batch: 281/911, Loss: 1.0745, Time: 3.02s\n",
      "Epoch: 3, Batch: 291/911, Loss: 0.8469, Time: 3.00s\n",
      "Epoch: 3, Batch: 301/911, Loss: 0.9194, Time: 3.04s\n",
      "Epoch: 3, Batch: 311/911, Loss: 0.9520, Time: 3.02s\n",
      "Epoch: 3, Batch: 321/911, Loss: 0.9105, Time: 2.99s\n",
      "Epoch: 3, Batch: 331/911, Loss: 0.8543, Time: 3.03s\n",
      "Epoch: 3, Batch: 341/911, Loss: 0.9587, Time: 3.01s\n",
      "Epoch: 3, Batch: 351/911, Loss: 1.0184, Time: 3.14s\n",
      "Epoch: 3, Batch: 361/911, Loss: 0.9127, Time: 3.07s\n",
      "Epoch: 3, Batch: 371/911, Loss: 1.2670, Time: 3.07s\n",
      "Epoch: 3, Batch: 381/911, Loss: 1.0163, Time: 3.13s\n",
      "Epoch: 3, Batch: 391/911, Loss: 1.0428, Time: 3.12s\n",
      "Epoch: 3, Batch: 401/911, Loss: 0.8401, Time: 3.05s\n",
      "Epoch: 3, Batch: 411/911, Loss: 0.7812, Time: 2.98s\n",
      "Epoch: 3, Batch: 421/911, Loss: 0.8313, Time: 3.03s\n",
      "Epoch: 3, Batch: 431/911, Loss: 0.7299, Time: 2.99s\n",
      "Epoch: 3, Batch: 441/911, Loss: 0.8342, Time: 3.02s\n",
      "Epoch: 3, Batch: 451/911, Loss: 1.0199, Time: 2.98s\n",
      "Epoch: 3, Batch: 461/911, Loss: 1.0288, Time: 2.98s\n",
      "Epoch: 3, Batch: 471/911, Loss: 0.9598, Time: 3.00s\n",
      "Epoch: 3, Batch: 481/911, Loss: 0.8933, Time: 2.98s\n",
      "Epoch: 3, Batch: 491/911, Loss: 1.1030, Time: 3.00s\n",
      "Epoch: 3, Batch: 501/911, Loss: 1.1419, Time: 3.02s\n",
      "Epoch: 3, Batch: 511/911, Loss: 0.9040, Time: 3.01s\n",
      "Epoch: 3, Batch: 521/911, Loss: 0.8736, Time: 3.02s\n",
      "Epoch: 3, Batch: 531/911, Loss: 0.7540, Time: 3.00s\n",
      "Epoch: 3, Batch: 541/911, Loss: 1.3035, Time: 3.00s\n",
      "Epoch: 3, Batch: 551/911, Loss: 1.0170, Time: 3.18s\n",
      "Epoch: 3, Batch: 561/911, Loss: 1.2203, Time: 3.11s\n",
      "Epoch: 3, Batch: 571/911, Loss: 0.9567, Time: 3.00s\n",
      "Epoch: 3, Batch: 581/911, Loss: 0.9552, Time: 3.03s\n",
      "Epoch: 3, Batch: 591/911, Loss: 0.7476, Time: 3.08s\n",
      "Epoch: 3, Batch: 601/911, Loss: 1.2282, Time: 3.09s\n",
      "Epoch: 3, Batch: 611/911, Loss: 1.0218, Time: 3.13s\n",
      "Epoch: 3, Batch: 621/911, Loss: 1.1747, Time: 3.15s\n",
      "Epoch: 3, Batch: 631/911, Loss: 0.8014, Time: 3.09s\n",
      "Epoch: 3, Batch: 641/911, Loss: 0.8508, Time: 3.12s\n",
      "Epoch: 3, Batch: 651/911, Loss: 0.6135, Time: 3.09s\n",
      "Epoch: 3, Batch: 661/911, Loss: 0.9018, Time: 3.19s\n",
      "Epoch: 3, Batch: 671/911, Loss: 0.7867, Time: 3.11s\n",
      "Epoch: 3, Batch: 681/911, Loss: 1.2907, Time: 3.12s\n",
      "Epoch: 3, Batch: 691/911, Loss: 0.7604, Time: 3.11s\n",
      "Epoch: 3, Batch: 701/911, Loss: 0.6919, Time: 3.12s\n",
      "Epoch: 3, Batch: 711/911, Loss: 0.8819, Time: 3.18s\n",
      "Epoch: 3, Batch: 721/911, Loss: 0.7403, Time: 3.11s\n",
      "Epoch: 3, Batch: 731/911, Loss: 0.8693, Time: 3.14s\n",
      "Epoch: 3, Batch: 741/911, Loss: 0.7247, Time: 3.11s\n",
      "Epoch: 3, Batch: 751/911, Loss: 0.9755, Time: 3.15s\n",
      "Epoch: 3, Batch: 761/911, Loss: 0.9466, Time: 3.03s\n",
      "Epoch: 3, Batch: 771/911, Loss: 0.8968, Time: 2.97s\n",
      "Epoch: 3, Batch: 781/911, Loss: 0.8404, Time: 3.00s\n",
      "Epoch: 3, Batch: 791/911, Loss: 1.0954, Time: 2.97s\n",
      "Epoch: 3, Batch: 801/911, Loss: 0.8036, Time: 2.98s\n",
      "Epoch: 3, Batch: 811/911, Loss: 0.8356, Time: 2.97s\n",
      "Epoch: 3, Batch: 821/911, Loss: 0.7553, Time: 3.00s\n",
      "Epoch: 3, Batch: 831/911, Loss: 1.1583, Time: 2.96s\n",
      "Epoch: 3, Batch: 841/911, Loss: 0.7698, Time: 3.01s\n",
      "Epoch: 3, Batch: 851/911, Loss: 0.7449, Time: 2.96s\n",
      "Epoch: 3, Batch: 861/911, Loss: 0.8854, Time: 3.00s\n",
      "Epoch: 3, Batch: 871/911, Loss: 0.8906, Time: 2.98s\n",
      "Epoch: 3, Batch: 881/911, Loss: 1.1848, Time: 2.98s\n",
      "Epoch: 3, Batch: 891/911, Loss: 0.7325, Time: 3.02s\n",
      "Epoch: 3, Batch: 901/911, Loss: 0.8702, Time: 3.00s\n",
      "Epoch: 3, Batch: 911/911, Loss: 1.0039, Time: 3.02s\n",
      "Epoch 3/100: Train Loss: 0.9325, Val Loss: 0.9747, Val IoU: 0.2090, Val Dice: 0.2594\n",
      "Saving best model with IoU: 0.2090\n",
      "Epoch: 4, Batch: 1/911, Loss: 0.7115, Time: 0.33s\n",
      "Epoch: 4, Batch: 11/911, Loss: 0.7997, Time: 2.96s\n",
      "Epoch: 4, Batch: 21/911, Loss: 0.9073, Time: 2.99s\n",
      "Epoch: 4, Batch: 31/911, Loss: 0.8075, Time: 2.97s\n",
      "Epoch: 4, Batch: 41/911, Loss: 1.0327, Time: 2.99s\n",
      "Epoch: 4, Batch: 51/911, Loss: 0.9895, Time: 2.99s\n",
      "Epoch: 4, Batch: 61/911, Loss: 0.8204, Time: 3.04s\n",
      "Epoch: 4, Batch: 71/911, Loss: 0.6402, Time: 3.10s\n",
      "Epoch: 4, Batch: 81/911, Loss: 1.0072, Time: 2.97s\n",
      "Epoch: 4, Batch: 91/911, Loss: 1.0006, Time: 2.96s\n",
      "Epoch: 4, Batch: 101/911, Loss: 0.8936, Time: 3.01s\n",
      "Epoch: 4, Batch: 111/911, Loss: 0.7501, Time: 3.01s\n",
      "Epoch: 4, Batch: 121/911, Loss: 0.9110, Time: 2.96s\n",
      "Epoch: 4, Batch: 131/911, Loss: 1.0814, Time: 2.97s\n",
      "Epoch: 4, Batch: 141/911, Loss: 0.8217, Time: 2.97s\n",
      "Epoch: 4, Batch: 151/911, Loss: 0.9410, Time: 2.97s\n",
      "Epoch: 4, Batch: 161/911, Loss: 1.0859, Time: 2.97s\n",
      "Epoch: 4, Batch: 171/911, Loss: 0.7429, Time: 3.00s\n",
      "Epoch: 4, Batch: 181/911, Loss: 1.2461, Time: 2.95s\n",
      "Epoch: 4, Batch: 191/911, Loss: 0.7900, Time: 2.96s\n",
      "Epoch: 4, Batch: 201/911, Loss: 1.0939, Time: 2.95s\n",
      "Epoch: 4, Batch: 211/911, Loss: 0.8770, Time: 2.98s\n",
      "Epoch: 4, Batch: 221/911, Loss: 0.8895, Time: 2.98s\n",
      "Epoch: 4, Batch: 231/911, Loss: 1.0612, Time: 2.97s\n",
      "Epoch: 4, Batch: 241/911, Loss: 0.7984, Time: 2.97s\n",
      "Epoch: 4, Batch: 251/911, Loss: 0.8699, Time: 2.99s\n",
      "Epoch: 4, Batch: 261/911, Loss: 0.6511, Time: 3.12s\n",
      "Epoch: 4, Batch: 271/911, Loss: 0.7194, Time: 3.13s\n",
      "Epoch: 4, Batch: 281/911, Loss: 0.9191, Time: 2.99s\n",
      "Epoch: 4, Batch: 291/911, Loss: 1.0028, Time: 2.97s\n",
      "Epoch: 4, Batch: 301/911, Loss: 0.8708, Time: 2.94s\n",
      "Epoch: 4, Batch: 311/911, Loss: 0.9913, Time: 2.99s\n",
      "Epoch: 4, Batch: 321/911, Loss: 0.9027, Time: 2.99s\n",
      "Epoch: 4, Batch: 331/911, Loss: 0.9149, Time: 2.95s\n",
      "Epoch: 4, Batch: 341/911, Loss: 1.0592, Time: 2.98s\n",
      "Epoch: 4, Batch: 351/911, Loss: 0.8974, Time: 2.96s\n",
      "Epoch: 4, Batch: 361/911, Loss: 0.8958, Time: 2.99s\n",
      "Epoch: 4, Batch: 371/911, Loss: 0.7653, Time: 3.00s\n",
      "Epoch: 4, Batch: 381/911, Loss: 0.9016, Time: 2.98s\n",
      "Epoch: 4, Batch: 391/911, Loss: 0.7844, Time: 3.00s\n",
      "Epoch: 4, Batch: 401/911, Loss: 0.6217, Time: 2.98s\n",
      "Epoch: 4, Batch: 411/911, Loss: 0.8669, Time: 2.96s\n",
      "Epoch: 4, Batch: 421/911, Loss: 1.0640, Time: 2.98s\n",
      "Epoch: 4, Batch: 431/911, Loss: 0.6959, Time: 2.98s\n",
      "Epoch: 4, Batch: 441/911, Loss: 0.7508, Time: 2.99s\n",
      "Epoch: 4, Batch: 451/911, Loss: 0.9379, Time: 2.94s\n",
      "Epoch: 4, Batch: 461/911, Loss: 0.9694, Time: 3.06s\n",
      "Epoch: 4, Batch: 471/911, Loss: 0.7177, Time: 3.11s\n",
      "Epoch: 4, Batch: 481/911, Loss: 0.8638, Time: 2.96s\n",
      "Epoch: 4, Batch: 491/911, Loss: 0.9099, Time: 3.03s\n",
      "Epoch: 4, Batch: 501/911, Loss: 0.9319, Time: 3.09s\n",
      "Epoch: 4, Batch: 511/911, Loss: 0.9405, Time: 3.08s\n",
      "Epoch: 4, Batch: 521/911, Loss: 1.1394, Time: 3.06s\n",
      "Epoch: 4, Batch: 531/911, Loss: 1.1739, Time: 3.06s\n",
      "Epoch: 4, Batch: 541/911, Loss: 0.9121, Time: 3.06s\n",
      "Epoch: 4, Batch: 551/911, Loss: 0.9286, Time: 3.08s\n",
      "Epoch: 4, Batch: 561/911, Loss: 0.9135, Time: 3.07s\n",
      "Epoch: 4, Batch: 571/911, Loss: 0.8275, Time: 3.08s\n",
      "Epoch: 4, Batch: 581/911, Loss: 0.7996, Time: 3.10s\n",
      "Epoch: 4, Batch: 591/911, Loss: 0.7316, Time: 3.07s\n",
      "Epoch: 4, Batch: 601/911, Loss: 0.8211, Time: 3.08s\n",
      "Epoch: 4, Batch: 611/911, Loss: 1.4245, Time: 3.08s\n",
      "Epoch: 4, Batch: 621/911, Loss: 0.8273, Time: 3.08s\n",
      "Epoch: 4, Batch: 631/911, Loss: 1.3400, Time: 3.08s\n",
      "Epoch: 4, Batch: 641/911, Loss: 0.8378, Time: 3.10s\n",
      "Epoch: 4, Batch: 651/911, Loss: 0.9607, Time: 2.96s\n",
      "Epoch: 4, Batch: 661/911, Loss: 0.9525, Time: 2.98s\n",
      "Epoch: 4, Batch: 671/911, Loss: 0.9887, Time: 3.05s\n",
      "Epoch: 4, Batch: 681/911, Loss: 0.7141, Time: 2.99s\n",
      "Epoch: 4, Batch: 691/911, Loss: 0.8874, Time: 2.99s\n",
      "Epoch: 4, Batch: 701/911, Loss: 1.1614, Time: 2.99s\n",
      "Epoch: 4, Batch: 711/911, Loss: 0.9362, Time: 2.96s\n",
      "Epoch: 4, Batch: 721/911, Loss: 0.7530, Time: 2.96s\n",
      "Epoch: 4, Batch: 731/911, Loss: 0.7351, Time: 2.97s\n",
      "Epoch: 4, Batch: 741/911, Loss: 0.7724, Time: 2.98s\n",
      "Epoch: 4, Batch: 751/911, Loss: 1.0920, Time: 2.95s\n",
      "Epoch: 4, Batch: 761/911, Loss: 0.8776, Time: 2.96s\n",
      "Epoch: 4, Batch: 771/911, Loss: 1.0039, Time: 2.97s\n",
      "Epoch: 4, Batch: 781/911, Loss: 0.7319, Time: 2.99s\n",
      "Epoch: 4, Batch: 791/911, Loss: 0.6629, Time: 2.96s\n",
      "Epoch: 4, Batch: 801/911, Loss: 0.8069, Time: 2.96s\n",
      "Epoch: 4, Batch: 811/911, Loss: 0.6262, Time: 2.96s\n",
      "Epoch: 4, Batch: 821/911, Loss: 0.9972, Time: 2.96s\n",
      "Epoch: 4, Batch: 831/911, Loss: 0.9748, Time: 2.96s\n",
      "Epoch: 4, Batch: 841/911, Loss: 0.9798, Time: 2.96s\n",
      "Epoch: 4, Batch: 851/911, Loss: 0.9063, Time: 2.99s\n",
      "Epoch: 4, Batch: 861/911, Loss: 0.7969, Time: 3.09s\n",
      "Epoch: 4, Batch: 871/911, Loss: 0.9315, Time: 3.06s\n",
      "Epoch: 4, Batch: 881/911, Loss: 0.9619, Time: 3.01s\n",
      "Epoch: 4, Batch: 891/911, Loss: 0.9276, Time: 3.00s\n",
      "Epoch: 4, Batch: 901/911, Loss: 0.7139, Time: 2.99s\n",
      "Epoch: 4, Batch: 911/911, Loss: 0.8104, Time: 2.97s\n",
      "Epoch 4/100: Train Loss: 0.8965, Val Loss: 0.9368, Val IoU: 0.2122, Val Dice: 0.2640\n",
      "Saving best model with IoU: 0.2122\n",
      "Epoch: 5, Batch: 1/911, Loss: 0.7793, Time: 0.33s\n",
      "Epoch: 5, Batch: 11/911, Loss: 0.8324, Time: 2.98s\n",
      "Epoch: 5, Batch: 21/911, Loss: 1.0371, Time: 3.19s\n",
      "Epoch: 5, Batch: 31/911, Loss: 0.7400, Time: 2.98s\n",
      "Epoch: 5, Batch: 41/911, Loss: 0.8171, Time: 2.96s\n",
      "Epoch: 5, Batch: 51/911, Loss: 0.9460, Time: 2.94s\n",
      "Epoch: 5, Batch: 61/911, Loss: 0.8962, Time: 2.95s\n",
      "Epoch: 5, Batch: 71/911, Loss: 0.7855, Time: 2.94s\n",
      "Epoch: 5, Batch: 81/911, Loss: 0.7943, Time: 2.97s\n",
      "Epoch: 5, Batch: 91/911, Loss: 0.7749, Time: 2.95s\n",
      "Epoch: 5, Batch: 101/911, Loss: 0.9030, Time: 2.95s\n",
      "Epoch: 5, Batch: 111/911, Loss: 0.8954, Time: 2.95s\n",
      "Epoch: 5, Batch: 121/911, Loss: 0.7630, Time: 2.96s\n",
      "Epoch: 5, Batch: 131/911, Loss: 0.7876, Time: 2.95s\n",
      "Epoch: 5, Batch: 141/911, Loss: 0.9293, Time: 2.95s\n",
      "Epoch: 5, Batch: 151/911, Loss: 1.0083, Time: 3.00s\n",
      "Epoch: 5, Batch: 161/911, Loss: 1.2039, Time: 2.95s\n",
      "Epoch: 5, Batch: 171/911, Loss: 1.1106, Time: 2.96s\n",
      "Epoch: 5, Batch: 181/911, Loss: 0.9049, Time: 3.04s\n",
      "Epoch: 5, Batch: 191/911, Loss: 0.8209, Time: 3.09s\n",
      "Epoch: 5, Batch: 201/911, Loss: 0.9176, Time: 2.98s\n",
      "Epoch: 5, Batch: 211/911, Loss: 0.7557, Time: 2.97s\n",
      "Epoch: 5, Batch: 221/911, Loss: 0.6910, Time: 2.96s\n",
      "Epoch: 5, Batch: 231/911, Loss: 0.7537, Time: 2.99s\n",
      "Epoch: 5, Batch: 241/911, Loss: 0.7284, Time: 2.96s\n",
      "Epoch: 5, Batch: 251/911, Loss: 1.0561, Time: 2.96s\n",
      "Epoch: 5, Batch: 261/911, Loss: 0.8294, Time: 2.96s\n",
      "Epoch: 5, Batch: 271/911, Loss: 0.8619, Time: 2.96s\n",
      "Epoch: 5, Batch: 281/911, Loss: 0.8210, Time: 3.00s\n",
      "Epoch: 5, Batch: 291/911, Loss: 0.9130, Time: 2.96s\n",
      "Epoch: 5, Batch: 301/911, Loss: 0.8081, Time: 2.97s\n",
      "Epoch: 5, Batch: 311/911, Loss: 0.7575, Time: 2.94s\n",
      "Epoch: 5, Batch: 321/911, Loss: 1.0055, Time: 2.94s\n",
      "Epoch: 5, Batch: 331/911, Loss: 0.8323, Time: 2.94s\n",
      "Epoch: 5, Batch: 341/911, Loss: 0.9589, Time: 3.00s\n",
      "Epoch: 5, Batch: 351/911, Loss: 0.8323, Time: 2.95s\n",
      "Epoch: 5, Batch: 361/911, Loss: 0.7782, Time: 2.93s\n",
      "Epoch: 5, Batch: 371/911, Loss: 0.8152, Time: 2.94s\n",
      "Epoch: 5, Batch: 381/911, Loss: 0.7890, Time: 3.01s\n",
      "Epoch: 5, Batch: 391/911, Loss: 0.9284, Time: 3.04s\n",
      "Epoch: 5, Batch: 401/911, Loss: 1.0106, Time: 2.95s\n",
      "Epoch: 5, Batch: 411/911, Loss: 1.0866, Time: 2.97s\n",
      "Epoch: 5, Batch: 421/911, Loss: 0.9414, Time: 2.96s\n",
      "Epoch: 5, Batch: 431/911, Loss: 0.8881, Time: 2.99s\n",
      "Epoch: 5, Batch: 441/911, Loss: 1.1528, Time: 3.02s\n",
      "Epoch: 5, Batch: 451/911, Loss: 0.9530, Time: 2.95s\n",
      "Epoch: 5, Batch: 461/911, Loss: 0.9107, Time: 2.95s\n",
      "Epoch: 5, Batch: 471/911, Loss: 0.7301, Time: 2.95s\n",
      "Epoch: 5, Batch: 481/911, Loss: 0.8893, Time: 2.95s\n",
      "Epoch: 5, Batch: 491/911, Loss: 1.1367, Time: 2.99s\n",
      "Epoch: 5, Batch: 501/911, Loss: 0.7291, Time: 2.98s\n",
      "Epoch: 5, Batch: 511/911, Loss: 0.7627, Time: 2.95s\n",
      "Epoch: 5, Batch: 521/911, Loss: 0.8220, Time: 2.99s\n",
      "Epoch: 5, Batch: 531/911, Loss: 0.6435, Time: 2.97s\n",
      "Epoch: 5, Batch: 541/911, Loss: 0.8099, Time: 2.95s\n",
      "Epoch: 5, Batch: 551/911, Loss: 0.9482, Time: 2.98s\n",
      "Epoch: 5, Batch: 561/911, Loss: 0.5288, Time: 3.05s\n",
      "Epoch: 5, Batch: 571/911, Loss: 0.7494, Time: 3.08s\n",
      "Epoch: 5, Batch: 581/911, Loss: 0.7811, Time: 3.10s\n",
      "Epoch: 5, Batch: 591/911, Loss: 0.8938, Time: 3.10s\n",
      "Epoch: 5, Batch: 601/911, Loss: 0.7780, Time: 3.07s\n",
      "Epoch: 5, Batch: 611/911, Loss: 0.8656, Time: 2.96s\n",
      "Epoch: 5, Batch: 621/911, Loss: 0.7181, Time: 2.97s\n",
      "Epoch: 5, Batch: 631/911, Loss: 0.8044, Time: 2.95s\n",
      "Epoch: 5, Batch: 641/911, Loss: 0.9019, Time: 2.95s\n",
      "Epoch: 5, Batch: 651/911, Loss: 0.6480, Time: 2.99s\n",
      "Epoch: 5, Batch: 661/911, Loss: 1.0104, Time: 2.96s\n",
      "Epoch: 5, Batch: 671/911, Loss: 0.7945, Time: 2.97s\n",
      "Epoch: 5, Batch: 681/911, Loss: 0.7315, Time: 2.96s\n",
      "Epoch: 5, Batch: 691/911, Loss: 0.6689, Time: 2.97s\n",
      "Epoch: 5, Batch: 701/911, Loss: 0.9857, Time: 2.95s\n",
      "Epoch: 5, Batch: 711/911, Loss: 0.9680, Time: 2.95s\n",
      "Epoch: 5, Batch: 721/911, Loss: 0.8078, Time: 2.98s\n",
      "Epoch: 5, Batch: 731/911, Loss: 0.9037, Time: 2.93s\n",
      "Epoch: 5, Batch: 741/911, Loss: 0.7374, Time: 2.96s\n",
      "Epoch: 5, Batch: 751/911, Loss: 0.7509, Time: 2.96s\n",
      "Epoch: 5, Batch: 761/911, Loss: 0.9299, Time: 2.97s\n",
      "Epoch: 5, Batch: 771/911, Loss: 0.6933, Time: 2.96s\n",
      "Epoch: 5, Batch: 781/911, Loss: 1.0963, Time: 3.07s\n",
      "Epoch: 5, Batch: 791/911, Loss: 0.6340, Time: 3.02s\n",
      "Epoch: 5, Batch: 801/911, Loss: 1.0007, Time: 3.09s\n",
      "Epoch: 5, Batch: 811/911, Loss: 0.8834, Time: 3.00s\n",
      "Epoch: 5, Batch: 821/911, Loss: 0.7726, Time: 2.97s\n",
      "Epoch: 5, Batch: 831/911, Loss: 1.0483, Time: 2.95s\n",
      "Epoch: 5, Batch: 841/911, Loss: 0.7964, Time: 2.97s\n",
      "Epoch: 5, Batch: 851/911, Loss: 0.9550, Time: 2.97s\n",
      "Epoch: 5, Batch: 861/911, Loss: 1.1243, Time: 2.96s\n",
      "Epoch: 5, Batch: 871/911, Loss: 0.6409, Time: 2.96s\n",
      "Epoch: 5, Batch: 881/911, Loss: 0.6981, Time: 2.97s\n",
      "Epoch: 5, Batch: 891/911, Loss: 0.9985, Time: 2.97s\n",
      "Epoch: 5, Batch: 901/911, Loss: 0.7458, Time: 2.98s\n",
      "Epoch: 5, Batch: 911/911, Loss: 0.8080, Time: 2.95s\n",
      "Epoch 5/100: Train Loss: 0.8713, Val Loss: 0.9702, Val IoU: 0.1992, Val Dice: 0.2489\n",
      "Epoch: 6, Batch: 1/911, Loss: 1.0117, Time: 0.33s\n",
      "Epoch: 6, Batch: 11/911, Loss: 0.7026, Time: 2.94s\n",
      "Epoch: 6, Batch: 21/911, Loss: 1.1848, Time: 2.97s\n",
      "Epoch: 6, Batch: 31/911, Loss: 0.8461, Time: 2.97s\n",
      "Epoch: 6, Batch: 41/911, Loss: 0.8328, Time: 2.97s\n",
      "Epoch: 6, Batch: 51/911, Loss: 0.8989, Time: 3.02s\n",
      "Epoch: 6, Batch: 61/911, Loss: 1.1825, Time: 2.98s\n",
      "Epoch: 6, Batch: 71/911, Loss: 0.6840, Time: 2.93s\n",
      "Epoch: 6, Batch: 81/911, Loss: 0.6633, Time: 2.95s\n",
      "Epoch: 6, Batch: 91/911, Loss: 0.6726, Time: 2.95s\n",
      "Epoch: 6, Batch: 101/911, Loss: 0.9781, Time: 2.99s\n",
      "Epoch: 6, Batch: 111/911, Loss: 0.9827, Time: 3.05s\n",
      "Epoch: 6, Batch: 121/911, Loss: 0.9743, Time: 3.01s\n",
      "Epoch: 6, Batch: 131/911, Loss: 1.0551, Time: 3.00s\n",
      "Epoch: 6, Batch: 141/911, Loss: 1.1490, Time: 2.96s\n",
      "Epoch: 6, Batch: 151/911, Loss: 0.8128, Time: 2.95s\n",
      "Epoch: 6, Batch: 161/911, Loss: 0.6637, Time: 2.97s\n",
      "Epoch: 6, Batch: 171/911, Loss: 1.0302, Time: 2.96s\n",
      "Epoch: 6, Batch: 181/911, Loss: 0.7866, Time: 2.95s\n",
      "Epoch: 6, Batch: 191/911, Loss: 0.8652, Time: 2.94s\n",
      "Epoch: 6, Batch: 201/911, Loss: 0.9524, Time: 2.95s\n",
      "Epoch: 6, Batch: 211/911, Loss: 0.6773, Time: 2.96s\n",
      "Epoch: 6, Batch: 221/911, Loss: 0.8642, Time: 2.94s\n",
      "Epoch: 6, Batch: 231/911, Loss: 0.8206, Time: 2.97s\n",
      "Epoch: 6, Batch: 241/911, Loss: 0.6292, Time: 2.96s\n",
      "Epoch: 6, Batch: 251/911, Loss: 0.7217, Time: 2.93s\n",
      "Epoch: 6, Batch: 261/911, Loss: 0.6248, Time: 2.96s\n",
      "Epoch: 6, Batch: 271/911, Loss: 0.8112, Time: 2.97s\n",
      "Epoch: 6, Batch: 281/911, Loss: 0.9757, Time: 2.93s\n",
      "Epoch: 6, Batch: 291/911, Loss: 0.7387, Time: 2.94s\n",
      "Epoch: 6, Batch: 301/911, Loss: 0.7139, Time: 2.96s\n",
      "Epoch: 6, Batch: 311/911, Loss: 0.8477, Time: 3.05s\n",
      "Epoch: 6, Batch: 321/911, Loss: 0.6322, Time: 3.06s\n",
      "Epoch: 6, Batch: 331/911, Loss: 0.9013, Time: 2.96s\n",
      "Epoch: 6, Batch: 341/911, Loss: 1.0050, Time: 2.95s\n",
      "Epoch: 6, Batch: 351/911, Loss: 0.6547, Time: 2.95s\n",
      "Epoch: 6, Batch: 361/911, Loss: 1.1464, Time: 2.95s\n",
      "Epoch: 6, Batch: 371/911, Loss: 0.7395, Time: 2.95s\n",
      "Epoch: 6, Batch: 381/911, Loss: 0.8446, Time: 2.97s\n",
      "Epoch: 6, Batch: 391/911, Loss: 0.6936, Time: 2.93s\n",
      "Epoch: 6, Batch: 401/911, Loss: 1.0234, Time: 2.95s\n",
      "Epoch: 6, Batch: 411/911, Loss: 0.8475, Time: 2.96s\n",
      "Epoch: 6, Batch: 421/911, Loss: 1.0091, Time: 2.94s\n",
      "Epoch: 6, Batch: 431/911, Loss: 1.0208, Time: 2.94s\n",
      "Epoch: 6, Batch: 441/911, Loss: 0.9232, Time: 2.95s\n",
      "Epoch: 6, Batch: 451/911, Loss: 0.7996, Time: 2.96s\n",
      "Epoch: 6, Batch: 461/911, Loss: 0.8625, Time: 3.00s\n",
      "Epoch: 6, Batch: 471/911, Loss: 0.7681, Time: 3.06s\n",
      "Epoch: 6, Batch: 481/911, Loss: 0.7734, Time: 3.06s\n",
      "Epoch: 6, Batch: 491/911, Loss: 0.8017, Time: 3.07s\n",
      "Epoch: 6, Batch: 501/911, Loss: 0.8265, Time: 3.07s\n",
      "Epoch: 6, Batch: 511/911, Loss: 0.9748, Time: 3.05s\n",
      "Epoch: 6, Batch: 521/911, Loss: 0.7661, Time: 3.08s\n",
      "Epoch: 6, Batch: 531/911, Loss: 0.9702, Time: 3.03s\n",
      "Epoch: 6, Batch: 541/911, Loss: 0.8262, Time: 3.04s\n",
      "Epoch: 6, Batch: 551/911, Loss: 0.9534, Time: 3.05s\n",
      "Epoch: 6, Batch: 561/911, Loss: 0.7837, Time: 3.06s\n",
      "Epoch: 6, Batch: 571/911, Loss: 0.7476, Time: 3.08s\n",
      "Epoch: 6, Batch: 581/911, Loss: 0.8810, Time: 3.08s\n",
      "Epoch: 6, Batch: 591/911, Loss: 0.7178, Time: 3.01s\n",
      "Epoch: 6, Batch: 601/911, Loss: 0.9327, Time: 2.95s\n",
      "Epoch: 6, Batch: 611/911, Loss: 0.7164, Time: 2.96s\n",
      "Epoch: 6, Batch: 621/911, Loss: 0.5850, Time: 3.00s\n",
      "Epoch: 6, Batch: 631/911, Loss: 1.0217, Time: 2.96s\n",
      "Epoch: 6, Batch: 641/911, Loss: 0.7526, Time: 2.95s\n",
      "Epoch: 6, Batch: 651/911, Loss: 0.7630, Time: 2.95s\n",
      "Epoch: 6, Batch: 661/911, Loss: 0.7974, Time: 2.97s\n",
      "Epoch: 6, Batch: 671/911, Loss: 0.8244, Time: 2.95s\n",
      "Epoch: 6, Batch: 681/911, Loss: 0.7157, Time: 2.95s\n",
      "Epoch: 6, Batch: 691/911, Loss: 0.9583, Time: 2.97s\n",
      "Epoch: 6, Batch: 701/911, Loss: 1.1945, Time: 2.94s\n",
      "Epoch: 6, Batch: 711/911, Loss: 0.7012, Time: 3.07s\n",
      "Epoch: 6, Batch: 721/911, Loss: 0.7485, Time: 3.05s\n",
      "Epoch: 6, Batch: 731/911, Loss: 0.8168, Time: 2.96s\n",
      "Epoch: 6, Batch: 741/911, Loss: 0.7313, Time: 3.00s\n",
      "Epoch: 6, Batch: 751/911, Loss: 0.6957, Time: 2.97s\n",
      "Epoch: 6, Batch: 761/911, Loss: 0.7394, Time: 2.97s\n",
      "Epoch: 6, Batch: 771/911, Loss: 0.6482, Time: 2.97s\n",
      "Epoch: 6, Batch: 781/911, Loss: 0.8242, Time: 2.96s\n",
      "Epoch: 6, Batch: 791/911, Loss: 1.1148, Time: 2.95s\n",
      "Epoch: 6, Batch: 801/911, Loss: 0.9623, Time: 2.94s\n",
      "Epoch: 6, Batch: 811/911, Loss: 0.9419, Time: 2.99s\n",
      "Epoch: 6, Batch: 821/911, Loss: 0.9029, Time: 2.96s\n",
      "Epoch: 6, Batch: 831/911, Loss: 0.6302, Time: 2.94s\n",
      "Epoch: 6, Batch: 841/911, Loss: 0.7249, Time: 2.98s\n",
      "Epoch: 6, Batch: 851/911, Loss: 0.7492, Time: 2.96s\n",
      "Epoch: 6, Batch: 861/911, Loss: 0.8316, Time: 2.97s\n",
      "Epoch: 6, Batch: 871/911, Loss: 0.7933, Time: 2.98s\n",
      "Epoch: 6, Batch: 881/911, Loss: 0.6674, Time: 2.97s\n",
      "Epoch: 6, Batch: 891/911, Loss: 0.8478, Time: 2.97s\n",
      "Epoch: 6, Batch: 901/911, Loss: 0.8931, Time: 2.97s\n",
      "Epoch: 6, Batch: 911/911, Loss: 0.8032, Time: 3.03s\n",
      "Epoch 6/100: Train Loss: 0.8402, Val Loss: 0.8715, Val IoU: 0.2149, Val Dice: 0.2669\n",
      "Saving best model with IoU: 0.2149\n",
      "Epoch: 7, Batch: 1/911, Loss: 0.6998, Time: 0.34s\n",
      "Epoch: 7, Batch: 11/911, Loss: 0.8749, Time: 2.95s\n",
      "Epoch: 7, Batch: 21/911, Loss: 0.8960, Time: 2.96s\n",
      "Epoch: 7, Batch: 31/911, Loss: 0.7955, Time: 3.07s\n",
      "Epoch: 7, Batch: 41/911, Loss: 0.7477, Time: 3.00s\n",
      "Epoch: 7, Batch: 51/911, Loss: 0.8089, Time: 3.02s\n",
      "Epoch: 7, Batch: 61/911, Loss: 0.8805, Time: 2.96s\n",
      "Epoch: 7, Batch: 71/911, Loss: 0.8179, Time: 2.97s\n",
      "Epoch: 7, Batch: 81/911, Loss: 0.7136, Time: 2.95s\n",
      "Epoch: 7, Batch: 91/911, Loss: 0.8894, Time: 2.97s\n",
      "Epoch: 7, Batch: 101/911, Loss: 1.0030, Time: 2.96s\n",
      "Epoch: 7, Batch: 111/911, Loss: 0.6736, Time: 2.95s\n",
      "Epoch: 7, Batch: 121/911, Loss: 0.8158, Time: 2.95s\n",
      "Epoch: 7, Batch: 131/911, Loss: 0.8249, Time: 2.98s\n",
      "Epoch: 7, Batch: 141/911, Loss: 0.7715, Time: 2.95s\n",
      "Epoch: 7, Batch: 151/911, Loss: 0.6557, Time: 2.96s\n",
      "Epoch: 7, Batch: 161/911, Loss: 0.6197, Time: 2.96s\n",
      "Epoch: 7, Batch: 171/911, Loss: 0.8458, Time: 2.96s\n",
      "Epoch: 7, Batch: 181/911, Loss: 0.9919, Time: 2.95s\n",
      "Epoch: 7, Batch: 191/911, Loss: 0.7476, Time: 3.01s\n",
      "Epoch: 7, Batch: 201/911, Loss: 0.6785, Time: 2.96s\n",
      "Epoch: 7, Batch: 211/911, Loss: 0.9555, Time: 2.95s\n",
      "Epoch: 7, Batch: 221/911, Loss: 0.8770, Time: 2.96s\n",
      "Epoch: 7, Batch: 231/911, Loss: 0.8937, Time: 3.00s\n",
      "Epoch: 7, Batch: 241/911, Loss: 0.6447, Time: 3.09s\n",
      "Epoch: 7, Batch: 251/911, Loss: 1.0278, Time: 3.01s\n",
      "Epoch: 7, Batch: 261/911, Loss: 0.8833, Time: 2.96s\n",
      "Epoch: 7, Batch: 271/911, Loss: 0.6616, Time: 2.95s\n",
      "Epoch: 7, Batch: 281/911, Loss: 0.8734, Time: 2.97s\n",
      "Epoch: 7, Batch: 291/911, Loss: 0.8648, Time: 2.95s\n",
      "Epoch: 7, Batch: 301/911, Loss: 0.9195, Time: 2.97s\n",
      "Epoch: 7, Batch: 311/911, Loss: 0.8489, Time: 2.95s\n",
      "Epoch: 7, Batch: 321/911, Loss: 0.9169, Time: 2.95s\n",
      "Epoch: 7, Batch: 331/911, Loss: 0.6406, Time: 2.94s\n",
      "Epoch: 7, Batch: 341/911, Loss: 0.9748, Time: 2.96s\n",
      "Epoch: 7, Batch: 351/911, Loss: 0.8838, Time: 2.95s\n",
      "Epoch: 7, Batch: 361/911, Loss: 0.9151, Time: 2.95s\n",
      "Epoch: 7, Batch: 371/911, Loss: 0.7068, Time: 2.94s\n",
      "Epoch: 7, Batch: 381/911, Loss: 0.8039, Time: 2.96s\n",
      "Epoch: 7, Batch: 391/911, Loss: 0.6616, Time: 2.96s\n",
      "Epoch: 7, Batch: 401/911, Loss: 0.6066, Time: 2.96s\n",
      "Epoch: 7, Batch: 411/911, Loss: 0.7250, Time: 2.94s\n",
      "Epoch: 7, Batch: 421/911, Loss: 1.1355, Time: 2.95s\n",
      "Epoch: 7, Batch: 431/911, Loss: 0.7787, Time: 2.93s\n",
      "Epoch: 7, Batch: 441/911, Loss: 0.8701, Time: 2.95s\n",
      "Epoch: 7, Batch: 451/911, Loss: 1.1437, Time: 2.97s\n",
      "Epoch: 7, Batch: 461/911, Loss: 0.7207, Time: 2.96s\n",
      "Epoch: 7, Batch: 471/911, Loss: 0.7082, Time: 2.94s\n",
      "Epoch: 7, Batch: 481/911, Loss: 1.0328, Time: 2.95s\n",
      "Epoch: 7, Batch: 491/911, Loss: 0.7420, Time: 2.95s\n",
      "Epoch: 7, Batch: 501/911, Loss: 0.8635, Time: 2.96s\n",
      "Epoch: 7, Batch: 511/911, Loss: 0.8238, Time: 2.96s\n",
      "Epoch: 7, Batch: 521/911, Loss: 1.0211, Time: 2.97s\n",
      "Epoch: 7, Batch: 531/911, Loss: 0.8536, Time: 2.96s\n",
      "Epoch: 7, Batch: 541/911, Loss: 0.8095, Time: 2.97s\n",
      "Epoch: 7, Batch: 551/911, Loss: 0.9527, Time: 2.95s\n",
      "Epoch: 7, Batch: 561/911, Loss: 0.7705, Time: 2.95s\n",
      "Epoch: 7, Batch: 571/911, Loss: 0.8926, Time: 2.96s\n",
      "Epoch: 7, Batch: 581/911, Loss: 1.0826, Time: 2.96s\n",
      "Epoch: 7, Batch: 591/911, Loss: 0.8502, Time: 2.93s\n",
      "Epoch: 7, Batch: 601/911, Loss: 0.8298, Time: 2.93s\n",
      "Epoch: 7, Batch: 611/911, Loss: 0.8019, Time: 2.95s\n",
      "Epoch: 7, Batch: 621/911, Loss: 1.0076, Time: 2.94s\n",
      "Epoch: 7, Batch: 631/911, Loss: 0.6636, Time: 2.94s\n",
      "Epoch: 7, Batch: 641/911, Loss: 0.6939, Time: 3.11s\n",
      "Epoch: 7, Batch: 651/911, Loss: 0.8726, Time: 3.03s\n",
      "Epoch: 7, Batch: 661/911, Loss: 0.7594, Time: 3.01s\n",
      "Epoch: 7, Batch: 671/911, Loss: 0.8266, Time: 2.98s\n",
      "Epoch: 7, Batch: 681/911, Loss: 0.7203, Time: 2.96s\n",
      "Epoch: 7, Batch: 691/911, Loss: 0.8439, Time: 2.95s\n",
      "Epoch: 7, Batch: 701/911, Loss: 0.7655, Time: 2.95s\n",
      "Epoch: 7, Batch: 711/911, Loss: 0.8100, Time: 2.96s\n",
      "Epoch: 7, Batch: 721/911, Loss: 0.8872, Time: 2.96s\n",
      "Epoch: 7, Batch: 731/911, Loss: 0.6456, Time: 2.94s\n",
      "Epoch: 7, Batch: 741/911, Loss: 0.7865, Time: 2.95s\n",
      "Epoch: 7, Batch: 751/911, Loss: 0.8184, Time: 2.95s\n",
      "Epoch: 7, Batch: 761/911, Loss: 0.6073, Time: 2.95s\n",
      "Epoch: 7, Batch: 771/911, Loss: 0.6769, Time: 2.98s\n",
      "Epoch: 7, Batch: 781/911, Loss: 0.8477, Time: 2.95s\n",
      "Epoch: 7, Batch: 791/911, Loss: 0.9199, Time: 2.96s\n",
      "Epoch: 7, Batch: 801/911, Loss: 0.6568, Time: 2.96s\n",
      "Epoch: 7, Batch: 811/911, Loss: 0.7760, Time: 2.96s\n",
      "Epoch: 7, Batch: 821/911, Loss: 0.7068, Time: 2.97s\n",
      "Epoch: 7, Batch: 831/911, Loss: 0.9660, Time: 2.98s\n",
      "Epoch: 7, Batch: 841/911, Loss: 0.9114, Time: 3.04s\n",
      "Epoch: 7, Batch: 851/911, Loss: 0.6555, Time: 3.09s\n",
      "Epoch: 7, Batch: 861/911, Loss: 0.8260, Time: 2.99s\n",
      "Epoch: 7, Batch: 871/911, Loss: 0.6078, Time: 2.95s\n",
      "Epoch: 7, Batch: 881/911, Loss: 0.6389, Time: 2.98s\n",
      "Epoch: 7, Batch: 891/911, Loss: 1.0427, Time: 2.96s\n",
      "Epoch: 7, Batch: 901/911, Loss: 0.7539, Time: 2.95s\n",
      "Epoch: 7, Batch: 911/911, Loss: 1.0096, Time: 2.96s\n",
      "Epoch 7/100: Train Loss: 0.8091, Val Loss: 0.9941, Val IoU: 0.1976, Val Dice: 0.2460\n",
      "Epoch: 8, Batch: 1/911, Loss: 0.7331, Time: 0.38s\n",
      "Epoch: 8, Batch: 11/911, Loss: 0.9429, Time: 2.95s\n",
      "Epoch: 8, Batch: 21/911, Loss: 1.0062, Time: 2.97s\n",
      "Epoch: 8, Batch: 31/911, Loss: 0.9485, Time: 2.95s\n",
      "Epoch: 8, Batch: 41/911, Loss: 0.7312, Time: 2.94s\n",
      "Epoch: 8, Batch: 51/911, Loss: 0.7814, Time: 2.97s\n",
      "Epoch: 8, Batch: 61/911, Loss: 0.8668, Time: 2.97s\n",
      "Epoch: 8, Batch: 71/911, Loss: 0.7004, Time: 2.95s\n",
      "Epoch: 8, Batch: 81/911, Loss: 0.6144, Time: 2.95s\n",
      "Epoch: 8, Batch: 91/911, Loss: 0.9815, Time: 2.95s\n",
      "Epoch: 8, Batch: 101/911, Loss: 0.7999, Time: 2.95s\n",
      "Epoch: 8, Batch: 111/911, Loss: 0.9479, Time: 2.97s\n",
      "Epoch: 8, Batch: 121/911, Loss: 0.8075, Time: 2.98s\n",
      "Epoch: 8, Batch: 131/911, Loss: 0.7600, Time: 2.96s\n",
      "Epoch: 8, Batch: 141/911, Loss: 0.6860, Time: 3.07s\n",
      "Epoch: 8, Batch: 151/911, Loss: 0.8304, Time: 2.97s\n",
      "Epoch: 8, Batch: 161/911, Loss: 0.7664, Time: 2.99s\n",
      "Epoch: 8, Batch: 171/911, Loss: 0.7016, Time: 3.08s\n",
      "Epoch: 8, Batch: 181/911, Loss: 0.6894, Time: 3.05s\n",
      "Epoch: 8, Batch: 191/911, Loss: 0.8043, Time: 2.98s\n",
      "Epoch: 8, Batch: 201/911, Loss: 0.8869, Time: 2.95s\n",
      "Epoch: 8, Batch: 211/911, Loss: 0.8412, Time: 2.96s\n",
      "Epoch: 8, Batch: 221/911, Loss: 0.6171, Time: 2.95s\n",
      "Epoch: 8, Batch: 231/911, Loss: 0.6720, Time: 2.96s\n",
      "Epoch: 8, Batch: 241/911, Loss: 0.7228, Time: 2.94s\n",
      "Epoch: 8, Batch: 251/911, Loss: 0.7506, Time: 2.95s\n",
      "Epoch: 8, Batch: 261/911, Loss: 0.9408, Time: 2.95s\n",
      "Epoch: 8, Batch: 271/911, Loss: 1.0015, Time: 2.94s\n",
      "Epoch: 8, Batch: 281/911, Loss: 0.6466, Time: 2.97s\n",
      "Epoch: 8, Batch: 291/911, Loss: 0.9665, Time: 2.96s\n",
      "Epoch: 8, Batch: 301/911, Loss: 0.7938, Time: 2.94s\n",
      "Epoch: 8, Batch: 311/911, Loss: 0.8702, Time: 2.97s\n",
      "Epoch: 8, Batch: 321/911, Loss: 0.8339, Time: 2.97s\n",
      "Epoch: 8, Batch: 331/911, Loss: 0.9465, Time: 2.94s\n",
      "Epoch: 8, Batch: 341/911, Loss: 0.6791, Time: 2.95s\n",
      "Epoch: 8, Batch: 351/911, Loss: 0.5843, Time: 2.96s\n",
      "Epoch: 8, Batch: 361/911, Loss: 0.7908, Time: 2.94s\n",
      "Epoch: 8, Batch: 371/911, Loss: 0.8810, Time: 2.94s\n",
      "Epoch: 8, Batch: 381/911, Loss: 1.0295, Time: 2.97s\n",
      "Epoch: 8, Batch: 391/911, Loss: 0.6700, Time: 2.95s\n",
      "Epoch: 8, Batch: 401/911, Loss: 0.8129, Time: 2.95s\n",
      "Epoch: 8, Batch: 411/911, Loss: 0.9573, Time: 2.96s\n",
      "Epoch: 8, Batch: 421/911, Loss: 0.7520, Time: 2.94s\n",
      "Epoch: 8, Batch: 431/911, Loss: 0.7828, Time: 2.94s\n",
      "Epoch: 8, Batch: 441/911, Loss: 0.7790, Time: 2.95s\n",
      "Epoch: 8, Batch: 451/911, Loss: 0.7746, Time: 2.97s\n",
      "Epoch: 8, Batch: 461/911, Loss: 0.6440, Time: 2.95s\n",
      "Epoch: 8, Batch: 471/911, Loss: 0.7243, Time: 2.96s\n",
      "Epoch: 8, Batch: 481/911, Loss: 0.6961, Time: 2.95s\n",
      "Epoch: 8, Batch: 491/911, Loss: 0.8384, Time: 2.97s\n",
      "Epoch: 8, Batch: 501/911, Loss: 0.7496, Time: 2.96s\n",
      "Epoch: 8, Batch: 511/911, Loss: 0.7459, Time: 2.94s\n",
      "Epoch: 8, Batch: 521/911, Loss: 0.7520, Time: 2.94s\n",
      "Epoch: 8, Batch: 531/911, Loss: 0.6814, Time: 2.96s\n",
      "Epoch: 8, Batch: 541/911, Loss: 0.4474, Time: 2.94s\n",
      "Epoch: 8, Batch: 551/911, Loss: 0.7257, Time: 2.94s\n",
      "Epoch: 8, Batch: 561/911, Loss: 0.9334, Time: 2.93s\n",
      "Epoch: 8, Batch: 571/911, Loss: 0.6035, Time: 3.04s\n",
      "Epoch: 8, Batch: 581/911, Loss: 0.7766, Time: 3.07s\n",
      "Epoch: 8, Batch: 591/911, Loss: 0.6195, Time: 2.96s\n",
      "Epoch: 8, Batch: 601/911, Loss: 0.6147, Time: 3.01s\n",
      "Epoch: 8, Batch: 611/911, Loss: 1.0890, Time: 2.96s\n",
      "Epoch: 8, Batch: 621/911, Loss: 0.7408, Time: 2.95s\n",
      "Epoch: 8, Batch: 631/911, Loss: 0.6100, Time: 2.96s\n",
      "Epoch: 8, Batch: 641/911, Loss: 0.6681, Time: 2.95s\n",
      "Epoch: 8, Batch: 651/911, Loss: 0.6869, Time: 2.95s\n",
      "Epoch: 8, Batch: 661/911, Loss: 0.7462, Time: 2.94s\n",
      "Epoch: 8, Batch: 671/911, Loss: 0.8322, Time: 2.97s\n",
      "Epoch: 8, Batch: 681/911, Loss: 0.8106, Time: 2.94s\n",
      "Epoch: 8, Batch: 691/911, Loss: 0.8080, Time: 2.95s\n",
      "Epoch: 8, Batch: 701/911, Loss: 0.7993, Time: 2.94s\n",
      "Epoch: 8, Batch: 711/911, Loss: 0.5763, Time: 2.98s\n",
      "Epoch: 8, Batch: 721/911, Loss: 0.8357, Time: 2.93s\n",
      "Epoch: 8, Batch: 731/911, Loss: 0.7151, Time: 2.94s\n",
      "Epoch: 8, Batch: 741/911, Loss: 0.7414, Time: 2.94s\n",
      "Epoch: 8, Batch: 751/911, Loss: 0.9270, Time: 2.95s\n",
      "Epoch: 8, Batch: 761/911, Loss: 0.6837, Time: 2.94s\n",
      "Epoch: 8, Batch: 771/911, Loss: 0.8807, Time: 3.02s\n",
      "Epoch: 8, Batch: 781/911, Loss: 0.7676, Time: 3.10s\n",
      "Epoch: 8, Batch: 791/911, Loss: 0.7504, Time: 3.07s\n",
      "Epoch: 8, Batch: 801/911, Loss: 0.8904, Time: 2.94s\n",
      "Epoch: 8, Batch: 811/911, Loss: 0.7637, Time: 2.96s\n",
      "Epoch: 8, Batch: 821/911, Loss: 0.8583, Time: 2.97s\n",
      "Epoch: 8, Batch: 831/911, Loss: 0.8126, Time: 2.95s\n",
      "Epoch: 8, Batch: 841/911, Loss: 0.5450, Time: 2.95s\n",
      "Epoch: 8, Batch: 851/911, Loss: 0.7112, Time: 2.94s\n",
      "Epoch: 8, Batch: 861/911, Loss: 1.4015, Time: 2.94s\n",
      "Epoch: 8, Batch: 871/911, Loss: 0.7306, Time: 2.95s\n",
      "Epoch: 8, Batch: 881/911, Loss: 0.7642, Time: 2.94s\n",
      "Epoch: 8, Batch: 891/911, Loss: 0.7478, Time: 2.95s\n",
      "Epoch: 8, Batch: 901/911, Loss: 1.0211, Time: 2.96s\n",
      "Epoch: 8, Batch: 911/911, Loss: 0.7956, Time: 2.93s\n",
      "Epoch 8/100: Train Loss: 0.7846, Val Loss: 0.8390, Val IoU: 0.2346, Val Dice: 0.2901\n",
      "Saving best model with IoU: 0.2346\n",
      "Epoch: 9, Batch: 1/911, Loss: 0.7363, Time: 0.33s\n",
      "Epoch: 9, Batch: 11/911, Loss: 0.8871, Time: 2.95s\n",
      "Epoch: 9, Batch: 21/911, Loss: 0.6992, Time: 2.97s\n",
      "Epoch: 9, Batch: 31/911, Loss: 0.5493, Time: 2.95s\n",
      "Epoch: 9, Batch: 41/911, Loss: 0.8167, Time: 2.95s\n",
      "Epoch: 9, Batch: 51/911, Loss: 0.5355, Time: 2.98s\n",
      "Epoch: 9, Batch: 61/911, Loss: 0.8236, Time: 2.97s\n",
      "Epoch: 9, Batch: 71/911, Loss: 0.6903, Time: 2.96s\n",
      "Epoch: 9, Batch: 81/911, Loss: 1.3066, Time: 2.96s\n",
      "Epoch: 9, Batch: 91/911, Loss: 1.1569, Time: 3.05s\n",
      "Epoch: 9, Batch: 101/911, Loss: 0.9632, Time: 3.02s\n",
      "Epoch: 9, Batch: 111/911, Loss: 0.8718, Time: 3.05s\n",
      "Epoch: 9, Batch: 121/911, Loss: 0.8217, Time: 2.95s\n",
      "Epoch: 9, Batch: 131/911, Loss: 0.6982, Time: 2.97s\n",
      "Epoch: 9, Batch: 141/911, Loss: 0.6978, Time: 2.97s\n",
      "Epoch: 9, Batch: 151/911, Loss: 0.9747, Time: 2.95s\n",
      "Epoch: 9, Batch: 161/911, Loss: 0.6620, Time: 2.95s\n",
      "Epoch: 9, Batch: 171/911, Loss: 0.8869, Time: 2.95s\n",
      "Epoch: 9, Batch: 181/911, Loss: 0.7398, Time: 2.95s\n",
      "Epoch: 9, Batch: 191/911, Loss: 1.0497, Time: 2.97s\n",
      "Epoch: 9, Batch: 201/911, Loss: 0.6700, Time: 2.96s\n",
      "Epoch: 9, Batch: 211/911, Loss: 0.8381, Time: 2.95s\n",
      "Epoch: 9, Batch: 221/911, Loss: 0.6147, Time: 2.94s\n",
      "Epoch: 9, Batch: 231/911, Loss: 0.9335, Time: 2.95s\n",
      "Epoch: 9, Batch: 241/911, Loss: 0.7888, Time: 2.94s\n",
      "Epoch: 9, Batch: 251/911, Loss: 0.5882, Time: 2.94s\n",
      "Epoch: 9, Batch: 261/911, Loss: 0.6093, Time: 2.96s\n",
      "Epoch: 9, Batch: 271/911, Loss: 0.5515, Time: 2.96s\n",
      "Epoch: 9, Batch: 281/911, Loss: 0.8196, Time: 2.95s\n",
      "Epoch: 9, Batch: 291/911, Loss: 0.8742, Time: 2.95s\n",
      "Epoch: 9, Batch: 301/911, Loss: 0.8379, Time: 2.96s\n",
      "Epoch: 9, Batch: 311/911, Loss: 0.5852, Time: 2.96s\n",
      "Epoch: 9, Batch: 321/911, Loss: 0.7638, Time: 2.95s\n",
      "Epoch: 9, Batch: 331/911, Loss: 0.7811, Time: 2.94s\n",
      "Epoch: 9, Batch: 341/911, Loss: 0.8404, Time: 2.96s\n",
      "Epoch: 9, Batch: 351/911, Loss: 0.8284, Time: 2.94s\n",
      "Epoch: 9, Batch: 361/911, Loss: 1.0057, Time: 2.97s\n",
      "Epoch: 9, Batch: 371/911, Loss: 0.7233, Time: 2.98s\n",
      "Epoch: 9, Batch: 381/911, Loss: 0.7770, Time: 2.95s\n",
      "Epoch: 9, Batch: 391/911, Loss: 0.6438, Time: 2.95s\n",
      "Epoch: 9, Batch: 401/911, Loss: 0.6767, Time: 2.94s\n",
      "Epoch: 9, Batch: 411/911, Loss: 0.8563, Time: 2.97s\n",
      "Epoch: 9, Batch: 421/911, Loss: 0.7279, Time: 2.96s\n",
      "Epoch: 9, Batch: 431/911, Loss: 0.9317, Time: 2.97s\n",
      "Epoch: 9, Batch: 441/911, Loss: 0.9891, Time: 2.94s\n",
      "Epoch: 9, Batch: 451/911, Loss: 0.7392, Time: 2.96s\n",
      "Epoch: 9, Batch: 461/911, Loss: 0.7159, Time: 2.94s\n",
      "Epoch: 9, Batch: 471/911, Loss: 0.6553, Time: 2.94s\n",
      "Epoch: 9, Batch: 481/911, Loss: 0.4479, Time: 2.95s\n",
      "Epoch: 9, Batch: 491/911, Loss: 1.0449, Time: 2.94s\n",
      "Epoch: 9, Batch: 501/911, Loss: 0.5363, Time: 3.09s\n",
      "Epoch: 9, Batch: 511/911, Loss: 0.6215, Time: 3.06s\n",
      "Epoch: 9, Batch: 521/911, Loss: 0.9310, Time: 3.08s\n",
      "Epoch: 9, Batch: 531/911, Loss: 0.8960, Time: 2.97s\n",
      "Epoch: 9, Batch: 541/911, Loss: 0.6684, Time: 2.95s\n",
      "Epoch: 9, Batch: 551/911, Loss: 0.5713, Time: 2.94s\n",
      "Epoch: 9, Batch: 561/911, Loss: 0.7196, Time: 2.95s\n",
      "Epoch: 9, Batch: 571/911, Loss: 0.7232, Time: 2.95s\n",
      "Epoch: 9, Batch: 581/911, Loss: 0.6456, Time: 2.94s\n",
      "Epoch: 9, Batch: 591/911, Loss: 0.8386, Time: 2.94s\n",
      "Epoch: 9, Batch: 601/911, Loss: 0.8716, Time: 2.97s\n",
      "Epoch: 9, Batch: 611/911, Loss: 0.7563, Time: 2.93s\n",
      "Epoch: 9, Batch: 621/911, Loss: 0.6393, Time: 2.95s\n",
      "Epoch: 9, Batch: 631/911, Loss: 0.8071, Time: 2.98s\n",
      "Epoch: 9, Batch: 641/911, Loss: 0.9432, Time: 2.94s\n",
      "Epoch: 9, Batch: 651/911, Loss: 0.9902, Time: 2.95s\n",
      "Epoch: 9, Batch: 661/911, Loss: 0.6969, Time: 2.96s\n",
      "Epoch: 9, Batch: 671/911, Loss: 0.6003, Time: 2.94s\n",
      "Epoch: 9, Batch: 681/911, Loss: 0.6439, Time: 2.97s\n",
      "Epoch: 9, Batch: 691/911, Loss: 0.7964, Time: 2.95s\n",
      "Epoch: 9, Batch: 701/911, Loss: 0.8366, Time: 3.04s\n",
      "Epoch: 9, Batch: 711/911, Loss: 0.8841, Time: 3.05s\n",
      "Epoch: 9, Batch: 721/911, Loss: 0.5087, Time: 2.97s\n",
      "Epoch: 9, Batch: 731/911, Loss: 0.6852, Time: 2.94s\n",
      "Epoch: 9, Batch: 741/911, Loss: 0.7732, Time: 2.98s\n",
      "Epoch: 9, Batch: 751/911, Loss: 0.5340, Time: 2.94s\n",
      "Epoch: 9, Batch: 761/911, Loss: 0.7225, Time: 2.94s\n",
      "Epoch: 9, Batch: 771/911, Loss: 0.7464, Time: 2.95s\n",
      "Epoch: 9, Batch: 781/911, Loss: 0.6989, Time: 2.93s\n",
      "Epoch: 9, Batch: 791/911, Loss: 1.0100, Time: 2.94s\n",
      "Epoch: 9, Batch: 801/911, Loss: 0.7510, Time: 2.96s\n",
      "Epoch: 9, Batch: 811/911, Loss: 0.5720, Time: 2.94s\n",
      "Epoch: 9, Batch: 821/911, Loss: 0.8532, Time: 2.95s\n",
      "Epoch: 9, Batch: 831/911, Loss: 0.6909, Time: 2.95s\n",
      "Epoch: 9, Batch: 841/911, Loss: 0.7959, Time: 2.95s\n",
      "Epoch: 9, Batch: 851/911, Loss: 0.7622, Time: 2.99s\n",
      "Epoch: 9, Batch: 861/911, Loss: 0.7241, Time: 2.95s\n",
      "Epoch: 9, Batch: 871/911, Loss: 0.6511, Time: 2.96s\n",
      "Epoch: 9, Batch: 881/911, Loss: 0.8010, Time: 2.95s\n",
      "Epoch: 9, Batch: 891/911, Loss: 0.7726, Time: 2.95s\n",
      "Epoch: 9, Batch: 901/911, Loss: 0.5022, Time: 2.98s\n",
      "Epoch: 9, Batch: 911/911, Loss: 0.8466, Time: 3.06s\n",
      "Epoch 9/100: Train Loss: 0.7648, Val Loss: 0.8207, Val IoU: 0.2372, Val Dice: 0.2924\n",
      "Saving best model with IoU: 0.2372\n",
      "Epoch: 10, Batch: 1/911, Loss: 0.6807, Time: 0.34s\n",
      "Epoch: 10, Batch: 11/911, Loss: 0.8178, Time: 2.94s\n",
      "Epoch: 10, Batch: 21/911, Loss: 0.7818, Time: 3.04s\n",
      "Epoch: 10, Batch: 31/911, Loss: 0.9034, Time: 3.02s\n",
      "Epoch: 10, Batch: 41/911, Loss: 0.6969, Time: 3.04s\n",
      "Epoch: 10, Batch: 51/911, Loss: 0.5695, Time: 2.96s\n",
      "Epoch: 10, Batch: 61/911, Loss: 0.7859, Time: 2.94s\n",
      "Epoch: 10, Batch: 71/911, Loss: 0.7043, Time: 2.95s\n",
      "Epoch: 10, Batch: 81/911, Loss: 0.7338, Time: 2.96s\n",
      "Epoch: 10, Batch: 91/911, Loss: 0.8376, Time: 2.94s\n",
      "Epoch: 10, Batch: 101/911, Loss: 0.6981, Time: 2.96s\n",
      "Epoch: 10, Batch: 111/911, Loss: 0.6274, Time: 2.94s\n",
      "Epoch: 10, Batch: 121/911, Loss: 0.6034, Time: 2.97s\n",
      "Epoch: 10, Batch: 131/911, Loss: 0.6935, Time: 2.96s\n",
      "Epoch: 10, Batch: 141/911, Loss: 0.8243, Time: 2.96s\n",
      "Epoch: 10, Batch: 151/911, Loss: 0.4665, Time: 2.94s\n",
      "Epoch: 10, Batch: 161/911, Loss: 0.8930, Time: 2.95s\n",
      "Epoch: 10, Batch: 171/911, Loss: 0.8365, Time: 2.96s\n",
      "Epoch: 10, Batch: 181/911, Loss: 0.6692, Time: 2.95s\n",
      "Epoch: 10, Batch: 191/911, Loss: 0.6451, Time: 2.94s\n",
      "Epoch: 10, Batch: 201/911, Loss: 0.7749, Time: 2.95s\n",
      "Epoch: 10, Batch: 211/911, Loss: 0.8666, Time: 2.95s\n",
      "Epoch: 10, Batch: 221/911, Loss: 0.7773, Time: 2.96s\n",
      "Epoch: 10, Batch: 231/911, Loss: 0.5993, Time: 2.95s\n",
      "Epoch: 10, Batch: 241/911, Loss: 0.7012, Time: 2.99s\n",
      "Epoch: 10, Batch: 251/911, Loss: 0.7741, Time: 2.96s\n",
      "Epoch: 10, Batch: 261/911, Loss: 0.6466, Time: 2.96s\n",
      "Epoch: 10, Batch: 271/911, Loss: 0.6031, Time: 2.97s\n",
      "Epoch: 10, Batch: 281/911, Loss: 0.7802, Time: 2.95s\n",
      "Epoch: 10, Batch: 291/911, Loss: 0.7385, Time: 2.95s\n",
      "Epoch: 10, Batch: 301/911, Loss: 0.6604, Time: 2.97s\n",
      "Epoch: 10, Batch: 311/911, Loss: 0.5602, Time: 2.95s\n",
      "Epoch: 10, Batch: 321/911, Loss: 0.6854, Time: 2.95s\n",
      "Epoch: 10, Batch: 331/911, Loss: 0.5607, Time: 2.95s\n",
      "Epoch: 10, Batch: 341/911, Loss: 0.8692, Time: 2.95s\n",
      "Epoch: 10, Batch: 351/911, Loss: 0.7532, Time: 2.99s\n",
      "Epoch: 10, Batch: 361/911, Loss: 0.6645, Time: 2.97s\n",
      "Epoch: 10, Batch: 371/911, Loss: 1.0727, Time: 2.94s\n",
      "Epoch: 10, Batch: 381/911, Loss: 0.7989, Time: 2.95s\n",
      "Epoch: 10, Batch: 391/911, Loss: 0.8624, Time: 2.96s\n",
      "Epoch: 10, Batch: 401/911, Loss: 0.6621, Time: 2.95s\n",
      "Epoch: 10, Batch: 411/911, Loss: 0.4995, Time: 2.95s\n",
      "Epoch: 10, Batch: 421/911, Loss: 0.6598, Time: 2.95s\n",
      "Epoch: 10, Batch: 431/911, Loss: 0.5130, Time: 3.07s\n",
      "Epoch: 10, Batch: 441/911, Loss: 0.7839, Time: 3.03s\n",
      "Epoch: 10, Batch: 451/911, Loss: 0.6971, Time: 2.97s\n",
      "Epoch: 10, Batch: 461/911, Loss: 0.5935, Time: 2.98s\n",
      "Epoch: 10, Batch: 471/911, Loss: 0.6554, Time: 2.96s\n",
      "Epoch: 10, Batch: 481/911, Loss: 0.6212, Time: 2.94s\n",
      "Epoch: 10, Batch: 491/911, Loss: 0.6759, Time: 2.95s\n",
      "Epoch: 10, Batch: 501/911, Loss: 0.7359, Time: 2.94s\n",
      "Epoch: 10, Batch: 511/911, Loss: 0.6922, Time: 2.95s\n",
      "Epoch: 10, Batch: 521/911, Loss: 0.6534, Time: 2.94s\n",
      "Epoch: 10, Batch: 531/911, Loss: 0.7250, Time: 2.96s\n",
      "Epoch: 10, Batch: 541/911, Loss: 0.8278, Time: 2.95s\n",
      "Epoch: 10, Batch: 551/911, Loss: 0.7813, Time: 2.94s\n",
      "Epoch: 10, Batch: 561/911, Loss: 0.6984, Time: 2.99s\n",
      "Epoch: 10, Batch: 571/911, Loss: 0.7380, Time: 2.95s\n",
      "Epoch: 10, Batch: 581/911, Loss: 0.6146, Time: 2.95s\n",
      "Epoch: 10, Batch: 591/911, Loss: 0.5136, Time: 2.95s\n",
      "Epoch: 10, Batch: 601/911, Loss: 0.7577, Time: 2.98s\n",
      "Epoch: 10, Batch: 611/911, Loss: 0.5631, Time: 2.94s\n",
      "Epoch: 10, Batch: 621/911, Loss: 0.7982, Time: 2.95s\n",
      "Epoch: 10, Batch: 631/911, Loss: 0.6783, Time: 3.00s\n",
      "Epoch: 10, Batch: 641/911, Loss: 0.7798, Time: 3.05s\n",
      "Epoch: 10, Batch: 651/911, Loss: 0.7731, Time: 3.03s\n",
      "Epoch: 10, Batch: 661/911, Loss: 0.7211, Time: 2.96s\n",
      "Epoch: 10, Batch: 671/911, Loss: 0.6432, Time: 2.96s\n",
      "Epoch: 10, Batch: 681/911, Loss: 0.6814, Time: 2.98s\n",
      "Epoch: 10, Batch: 691/911, Loss: 0.9305, Time: 2.95s\n",
      "Epoch: 10, Batch: 701/911, Loss: 0.5791, Time: 2.96s\n",
      "Epoch: 10, Batch: 711/911, Loss: 0.7411, Time: 2.94s\n",
      "Epoch: 10, Batch: 721/911, Loss: 0.6557, Time: 2.95s\n",
      "Epoch: 10, Batch: 731/911, Loss: 0.6949, Time: 2.96s\n",
      "Epoch: 10, Batch: 741/911, Loss: 0.6535, Time: 2.94s\n",
      "Epoch: 10, Batch: 751/911, Loss: 0.7167, Time: 2.94s\n",
      "Epoch: 10, Batch: 761/911, Loss: 0.9138, Time: 2.95s\n",
      "Epoch: 10, Batch: 771/911, Loss: 0.5301, Time: 2.94s\n",
      "Epoch: 10, Batch: 781/911, Loss: 0.6318, Time: 2.97s\n",
      "Epoch: 10, Batch: 791/911, Loss: 0.7578, Time: 2.96s\n",
      "Epoch: 10, Batch: 801/911, Loss: 0.8085, Time: 2.97s\n",
      "Epoch: 10, Batch: 811/911, Loss: 0.7977, Time: 2.95s\n",
      "Epoch: 10, Batch: 821/911, Loss: 0.5842, Time: 2.95s\n",
      "Epoch: 10, Batch: 831/911, Loss: 0.7123, Time: 3.01s\n",
      "Epoch: 10, Batch: 841/911, Loss: 1.0306, Time: 3.02s\n",
      "Epoch: 10, Batch: 851/911, Loss: 0.7595, Time: 3.03s\n",
      "Epoch: 10, Batch: 861/911, Loss: 0.7557, Time: 2.94s\n",
      "Epoch: 10, Batch: 871/911, Loss: 0.8347, Time: 2.94s\n",
      "Epoch: 10, Batch: 881/911, Loss: 0.7639, Time: 2.95s\n",
      "Epoch: 10, Batch: 891/911, Loss: 0.6125, Time: 2.98s\n",
      "Epoch: 10, Batch: 901/911, Loss: 0.6694, Time: 2.95s\n",
      "Epoch: 10, Batch: 911/911, Loss: 0.6664, Time: 2.95s\n",
      "Epoch 10/100: Train Loss: 0.7378, Val Loss: 0.7880, Val IoU: 0.2368, Val Dice: 0.2919\n",
      "Epoch: 11, Batch: 1/911, Loss: 0.7033, Time: 0.42s\n",
      "Epoch: 11, Batch: 11/911, Loss: 0.6404, Time: 2.94s\n",
      "Epoch: 11, Batch: 21/911, Loss: 0.8025, Time: 2.93s\n",
      "Epoch: 11, Batch: 31/911, Loss: 0.6461, Time: 2.94s\n",
      "Epoch: 11, Batch: 41/911, Loss: 0.7040, Time: 2.94s\n",
      "Epoch: 11, Batch: 51/911, Loss: 0.7166, Time: 2.98s\n",
      "Epoch: 11, Batch: 61/911, Loss: 0.7176, Time: 2.95s\n",
      "Epoch: 11, Batch: 71/911, Loss: 0.7225, Time: 2.96s\n",
      "Epoch: 11, Batch: 81/911, Loss: 0.5937, Time: 2.94s\n",
      "Epoch: 11, Batch: 91/911, Loss: 0.7125, Time: 2.97s\n",
      "Epoch: 11, Batch: 101/911, Loss: 0.8196, Time: 2.94s\n",
      "Epoch: 11, Batch: 111/911, Loss: 0.7881, Time: 2.94s\n",
      "Epoch: 11, Batch: 121/911, Loss: 0.7917, Time: 2.94s\n",
      "Epoch: 11, Batch: 131/911, Loss: 0.6533, Time: 2.94s\n",
      "Epoch: 11, Batch: 141/911, Loss: 0.8409, Time: 2.97s\n",
      "Epoch: 11, Batch: 151/911, Loss: 0.7764, Time: 3.03s\n",
      "Epoch: 11, Batch: 161/911, Loss: 0.8312, Time: 3.09s\n",
      "Epoch: 11, Batch: 171/911, Loss: 0.7005, Time: 3.05s\n",
      "Epoch: 11, Batch: 181/911, Loss: 0.7787, Time: 3.04s\n",
      "Epoch: 11, Batch: 191/911, Loss: 0.7488, Time: 2.97s\n",
      "Epoch: 11, Batch: 201/911, Loss: 0.8705, Time: 2.94s\n",
      "Epoch: 11, Batch: 211/911, Loss: 0.7638, Time: 2.96s\n",
      "Epoch: 11, Batch: 221/911, Loss: 0.6872, Time: 2.95s\n",
      "Epoch: 11, Batch: 231/911, Loss: 0.5763, Time: 2.94s\n",
      "Epoch: 11, Batch: 241/911, Loss: 0.6671, Time: 2.95s\n",
      "Epoch: 11, Batch: 251/911, Loss: 0.5774, Time: 2.95s\n",
      "Epoch: 11, Batch: 261/911, Loss: 0.8762, Time: 2.95s\n",
      "Epoch: 11, Batch: 271/911, Loss: 0.8021, Time: 2.95s\n",
      "Epoch: 11, Batch: 281/911, Loss: 0.9549, Time: 3.07s\n",
      "Epoch: 11, Batch: 291/911, Loss: 0.8887, Time: 2.96s\n",
      "Epoch: 11, Batch: 301/911, Loss: 0.8032, Time: 2.95s\n",
      "Epoch: 11, Batch: 311/911, Loss: 0.5336, Time: 2.95s\n",
      "Epoch: 11, Batch: 321/911, Loss: 0.7943, Time: 2.95s\n",
      "Epoch: 11, Batch: 331/911, Loss: 0.7213, Time: 2.94s\n",
      "Epoch: 11, Batch: 341/911, Loss: 0.8024, Time: 2.94s\n",
      "Epoch: 11, Batch: 351/911, Loss: 0.7895, Time: 2.95s\n",
      "Epoch: 11, Batch: 361/911, Loss: 0.6860, Time: 3.07s\n",
      "Epoch: 11, Batch: 371/911, Loss: 0.8097, Time: 3.02s\n",
      "Epoch: 11, Batch: 381/911, Loss: 0.6817, Time: 2.95s\n",
      "Epoch: 11, Batch: 391/911, Loss: 0.5314, Time: 2.99s\n",
      "Epoch: 11, Batch: 401/911, Loss: 0.6636, Time: 2.96s\n",
      "Epoch: 11, Batch: 411/911, Loss: 0.5984, Time: 2.94s\n",
      "Epoch: 11, Batch: 421/911, Loss: 0.6585, Time: 2.97s\n",
      "Epoch: 11, Batch: 431/911, Loss: 0.6250, Time: 2.96s\n",
      "Epoch: 11, Batch: 441/911, Loss: 0.7492, Time: 2.96s\n",
      "Epoch: 11, Batch: 451/911, Loss: 0.8144, Time: 2.95s\n",
      "Epoch: 11, Batch: 461/911, Loss: 0.7367, Time: 2.95s\n",
      "Epoch: 11, Batch: 471/911, Loss: 0.7960, Time: 2.95s\n",
      "Epoch: 11, Batch: 481/911, Loss: 0.6690, Time: 2.94s\n",
      "Epoch: 11, Batch: 491/911, Loss: 0.6556, Time: 2.94s\n",
      "Epoch: 11, Batch: 501/911, Loss: 0.5074, Time: 2.99s\n",
      "Epoch: 11, Batch: 511/911, Loss: 0.7816, Time: 2.95s\n",
      "Epoch: 11, Batch: 521/911, Loss: 0.7616, Time: 2.95s\n",
      "Epoch: 11, Batch: 531/911, Loss: 0.5711, Time: 2.94s\n",
      "Epoch: 11, Batch: 541/911, Loss: 0.5482, Time: 2.95s\n",
      "Epoch: 11, Batch: 551/911, Loss: 0.7191, Time: 2.95s\n",
      "Epoch: 11, Batch: 561/911, Loss: 0.8168, Time: 3.03s\n",
      "Epoch: 11, Batch: 571/911, Loss: 0.7204, Time: 3.06s\n",
      "Epoch: 11, Batch: 581/911, Loss: 0.7640, Time: 2.95s\n",
      "Epoch: 11, Batch: 591/911, Loss: 0.8691, Time: 2.95s\n",
      "Epoch: 11, Batch: 601/911, Loss: 0.8199, Time: 2.94s\n",
      "Epoch: 11, Batch: 611/911, Loss: 0.7135, Time: 2.98s\n",
      "Epoch: 11, Batch: 621/911, Loss: 0.8781, Time: 2.94s\n",
      "Epoch: 11, Batch: 631/911, Loss: 0.6351, Time: 2.93s\n",
      "Epoch: 11, Batch: 641/911, Loss: 0.7207, Time: 2.95s\n",
      "Epoch: 11, Batch: 651/911, Loss: 0.7867, Time: 2.94s\n",
      "Epoch: 11, Batch: 661/911, Loss: 0.8132, Time: 2.96s\n",
      "Epoch: 11, Batch: 671/911, Loss: 0.8032, Time: 2.94s\n",
      "Epoch: 11, Batch: 681/911, Loss: 0.7436, Time: 2.94s\n",
      "Epoch: 11, Batch: 691/911, Loss: 0.8507, Time: 2.95s\n",
      "Epoch: 11, Batch: 701/911, Loss: 0.5009, Time: 2.96s\n",
      "Epoch: 11, Batch: 711/911, Loss: 0.7193, Time: 2.95s\n",
      "Epoch: 11, Batch: 721/911, Loss: 0.8131, Time: 2.96s\n",
      "Epoch: 11, Batch: 731/911, Loss: 0.6483, Time: 2.94s\n",
      "Epoch: 11, Batch: 741/911, Loss: 0.9218, Time: 2.94s\n",
      "Epoch: 11, Batch: 751/911, Loss: 0.7230, Time: 2.95s\n",
      "Epoch: 11, Batch: 761/911, Loss: 0.5965, Time: 2.97s\n",
      "Epoch: 11, Batch: 771/911, Loss: 0.9502, Time: 3.03s\n",
      "Epoch: 11, Batch: 781/911, Loss: 0.6403, Time: 3.02s\n",
      "Epoch: 11, Batch: 791/911, Loss: 0.7295, Time: 2.95s\n",
      "Epoch: 11, Batch: 801/911, Loss: 0.6281, Time: 2.94s\n",
      "Epoch: 11, Batch: 811/911, Loss: 0.7344, Time: 2.96s\n",
      "Epoch: 11, Batch: 821/911, Loss: 0.7131, Time: 3.02s\n",
      "Epoch: 11, Batch: 831/911, Loss: 0.6707, Time: 2.97s\n",
      "Epoch: 11, Batch: 841/911, Loss: 0.5441, Time: 2.95s\n",
      "Epoch: 11, Batch: 851/911, Loss: 0.6567, Time: 2.94s\n",
      "Epoch: 11, Batch: 861/911, Loss: 0.7213, Time: 2.95s\n",
      "Epoch: 11, Batch: 871/911, Loss: 0.7549, Time: 2.96s\n",
      "Epoch: 11, Batch: 881/911, Loss: 0.6728, Time: 2.95s\n",
      "Epoch: 11, Batch: 891/911, Loss: 0.7693, Time: 2.94s\n",
      "Epoch: 11, Batch: 901/911, Loss: 0.6304, Time: 2.93s\n",
      "Epoch: 11, Batch: 911/911, Loss: 0.7267, Time: 2.96s\n",
      "Epoch 11/100: Train Loss: 0.7200, Val Loss: 0.9085, Val IoU: 0.2159, Val Dice: 0.2668\n",
      "Epoch: 12, Batch: 1/911, Loss: 0.5457, Time: 0.32s\n",
      "Epoch: 12, Batch: 11/911, Loss: 0.6995, Time: 2.95s\n",
      "Epoch: 12, Batch: 21/911, Loss: 0.8418, Time: 2.94s\n",
      "Epoch: 12, Batch: 31/911, Loss: 0.8700, Time: 2.94s\n",
      "Epoch: 12, Batch: 41/911, Loss: 0.6658, Time: 2.95s\n",
      "Epoch: 12, Batch: 51/911, Loss: 0.7303, Time: 2.95s\n",
      "Epoch: 12, Batch: 61/911, Loss: 0.5786, Time: 2.93s\n",
      "Epoch: 12, Batch: 71/911, Loss: 0.7360, Time: 2.96s\n",
      "Epoch: 12, Batch: 81/911, Loss: 0.5741, Time: 2.95s\n",
      "Epoch: 12, Batch: 91/911, Loss: 0.5590, Time: 2.94s\n",
      "Epoch: 12, Batch: 101/911, Loss: 0.7425, Time: 2.94s\n",
      "Epoch: 12, Batch: 111/911, Loss: 0.8123, Time: 2.97s\n",
      "Epoch: 12, Batch: 121/911, Loss: 1.0436, Time: 2.94s\n",
      "Epoch: 12, Batch: 131/911, Loss: 0.6134, Time: 2.95s\n",
      "Epoch: 12, Batch: 141/911, Loss: 0.6959, Time: 2.98s\n",
      "Epoch: 12, Batch: 151/911, Loss: 0.9562, Time: 2.95s\n",
      "Epoch: 12, Batch: 161/911, Loss: 0.9103, Time: 2.94s\n",
      "Epoch: 12, Batch: 171/911, Loss: 0.4996, Time: 2.94s\n",
      "Epoch: 12, Batch: 181/911, Loss: 0.8160, Time: 2.95s\n",
      "Epoch: 12, Batch: 191/911, Loss: 0.6902, Time: 2.94s\n",
      "Epoch: 12, Batch: 201/911, Loss: 0.8574, Time: 2.95s\n",
      "Epoch: 12, Batch: 211/911, Loss: 0.5919, Time: 2.99s\n",
      "Epoch: 12, Batch: 221/911, Loss: 0.7602, Time: 2.95s\n",
      "Epoch: 12, Batch: 231/911, Loss: 0.8041, Time: 2.94s\n",
      "Epoch: 12, Batch: 241/911, Loss: 0.7262, Time: 2.95s\n",
      "Epoch: 12, Batch: 251/911, Loss: 0.5499, Time: 2.96s\n",
      "Epoch: 12, Batch: 261/911, Loss: 0.7257, Time: 2.96s\n",
      "Epoch: 12, Batch: 271/911, Loss: 0.6806, Time: 2.96s\n",
      "Epoch: 12, Batch: 281/911, Loss: 0.8248, Time: 2.95s\n",
      "Epoch: 12, Batch: 291/911, Loss: 0.8732, Time: 3.11s\n",
      "Epoch: 12, Batch: 301/911, Loss: 0.5349, Time: 3.08s\n",
      "Epoch: 12, Batch: 311/911, Loss: 0.6214, Time: 3.05s\n",
      "Epoch: 12, Batch: 321/911, Loss: 0.4826, Time: 3.01s\n",
      "Epoch: 12, Batch: 331/911, Loss: 0.5918, Time: 2.95s\n",
      "Epoch: 12, Batch: 341/911, Loss: 0.7315, Time: 2.95s\n",
      "Epoch: 12, Batch: 351/911, Loss: 0.5612, Time: 2.95s\n",
      "Epoch: 12, Batch: 361/911, Loss: 0.7932, Time: 2.95s\n",
      "Epoch: 12, Batch: 371/911, Loss: 0.6332, Time: 2.96s\n",
      "Epoch: 12, Batch: 381/911, Loss: 0.8669, Time: 2.95s\n",
      "Epoch: 12, Batch: 391/911, Loss: 0.7082, Time: 2.99s\n",
      "Epoch: 12, Batch: 401/911, Loss: 0.7695, Time: 2.96s\n",
      "Epoch: 12, Batch: 411/911, Loss: 0.7983, Time: 2.94s\n",
      "Epoch: 12, Batch: 421/911, Loss: 0.6252, Time: 2.96s\n",
      "Epoch: 12, Batch: 431/911, Loss: 0.8246, Time: 3.00s\n",
      "Epoch: 12, Batch: 441/911, Loss: 0.5519, Time: 2.94s\n",
      "Epoch: 12, Batch: 451/911, Loss: 0.5539, Time: 2.94s\n",
      "Epoch: 12, Batch: 461/911, Loss: 0.7813, Time: 2.96s\n",
      "Epoch: 12, Batch: 471/911, Loss: 0.9455, Time: 2.96s\n",
      "Epoch: 12, Batch: 481/911, Loss: 0.8607, Time: 2.96s\n",
      "Epoch: 12, Batch: 491/911, Loss: 0.7803, Time: 3.03s\n",
      "Epoch: 12, Batch: 501/911, Loss: 0.8019, Time: 3.04s\n",
      "Epoch: 12, Batch: 511/911, Loss: 0.8349, Time: 3.03s\n",
      "Epoch: 12, Batch: 521/911, Loss: 0.5942, Time: 2.97s\n",
      "Epoch: 12, Batch: 531/911, Loss: 0.4335, Time: 2.95s\n",
      "Epoch: 12, Batch: 541/911, Loss: 0.5671, Time: 2.98s\n",
      "Epoch: 12, Batch: 551/911, Loss: 0.6757, Time: 2.97s\n",
      "Epoch: 12, Batch: 561/911, Loss: 0.6244, Time: 2.96s\n",
      "Epoch: 12, Batch: 571/911, Loss: 0.5784, Time: 2.97s\n",
      "Epoch: 12, Batch: 581/911, Loss: 0.7640, Time: 2.97s\n",
      "Epoch: 12, Batch: 591/911, Loss: 0.5899, Time: 2.98s\n",
      "Epoch: 12, Batch: 601/911, Loss: 0.7492, Time: 2.97s\n",
      "Epoch: 12, Batch: 611/911, Loss: 0.7764, Time: 2.96s\n",
      "Epoch: 12, Batch: 621/911, Loss: 0.7664, Time: 2.94s\n",
      "Epoch: 12, Batch: 631/911, Loss: 0.6074, Time: 2.96s\n",
      "Epoch: 12, Batch: 641/911, Loss: 0.7481, Time: 2.98s\n",
      "Epoch: 12, Batch: 651/911, Loss: 0.6167, Time: 2.97s\n",
      "Epoch: 12, Batch: 661/911, Loss: 0.8256, Time: 2.94s\n",
      "Epoch: 12, Batch: 671/911, Loss: 0.6945, Time: 2.96s\n",
      "Epoch: 12, Batch: 681/911, Loss: 0.8729, Time: 2.94s\n",
      "Epoch: 12, Batch: 691/911, Loss: 0.7367, Time: 3.00s\n",
      "Epoch: 12, Batch: 701/911, Loss: 0.6390, Time: 3.06s\n",
      "Epoch: 12, Batch: 711/911, Loss: 0.8828, Time: 3.02s\n",
      "Epoch: 12, Batch: 721/911, Loss: 0.8728, Time: 2.95s\n",
      "Epoch: 12, Batch: 731/911, Loss: 0.7636, Time: 2.96s\n",
      "Epoch: 12, Batch: 741/911, Loss: 0.7094, Time: 2.95s\n",
      "Epoch: 12, Batch: 751/911, Loss: 0.5697, Time: 2.98s\n",
      "Epoch: 12, Batch: 761/911, Loss: 0.5270, Time: 2.95s\n",
      "Epoch: 12, Batch: 771/911, Loss: 0.6298, Time: 2.95s\n",
      "Epoch: 12, Batch: 781/911, Loss: 0.4634, Time: 2.94s\n",
      "Epoch: 12, Batch: 791/911, Loss: 0.7029, Time: 2.95s\n",
      "Epoch: 12, Batch: 801/911, Loss: 0.4997, Time: 2.94s\n",
      "Epoch: 12, Batch: 811/911, Loss: 0.6287, Time: 2.95s\n",
      "Epoch: 12, Batch: 821/911, Loss: 0.8651, Time: 2.94s\n",
      "Epoch: 12, Batch: 831/911, Loss: 0.8628, Time: 2.95s\n",
      "Epoch: 12, Batch: 841/911, Loss: 0.8128, Time: 2.95s\n",
      "Epoch: 12, Batch: 851/911, Loss: 0.8063, Time: 2.96s\n",
      "Epoch: 12, Batch: 861/911, Loss: 0.6773, Time: 2.99s\n",
      "Epoch: 12, Batch: 871/911, Loss: 0.6697, Time: 2.96s\n",
      "Epoch: 12, Batch: 881/911, Loss: 0.5521, Time: 2.95s\n",
      "Epoch: 12, Batch: 891/911, Loss: 0.5559, Time: 2.95s\n",
      "Epoch: 12, Batch: 901/911, Loss: 0.8861, Time: 3.11s\n",
      "Epoch: 12, Batch: 911/911, Loss: 0.6470, Time: 3.08s\n",
      "Epoch 12/100: Train Loss: 0.6992, Val Loss: 0.7461, Val IoU: 0.2546, Val Dice: 0.3114\n",
      "Saving best model with IoU: 0.2546\n",
      "Epoch: 13, Batch: 1/911, Loss: 0.5976, Time: 0.33s\n",
      "Epoch: 13, Batch: 11/911, Loss: 0.5718, Time: 2.94s\n",
      "Epoch: 13, Batch: 21/911, Loss: 0.5871, Time: 2.97s\n",
      "Epoch: 13, Batch: 31/911, Loss: 0.7272, Time: 2.95s\n",
      "Epoch: 13, Batch: 41/911, Loss: 0.7451, Time: 2.96s\n",
      "Epoch: 13, Batch: 51/911, Loss: 0.8034, Time: 2.95s\n",
      "Epoch: 13, Batch: 61/911, Loss: 0.6124, Time: 2.95s\n",
      "Epoch: 13, Batch: 71/911, Loss: 0.5139, Time: 2.96s\n",
      "Epoch: 13, Batch: 81/911, Loss: 0.6550, Time: 2.97s\n",
      "Epoch: 13, Batch: 91/911, Loss: 0.5805, Time: 2.95s\n",
      "Epoch: 13, Batch: 101/911, Loss: 0.6144, Time: 2.94s\n",
      "Epoch: 13, Batch: 111/911, Loss: 0.7855, Time: 2.95s\n",
      "Epoch: 13, Batch: 121/911, Loss: 0.6282, Time: 2.94s\n",
      "Epoch: 13, Batch: 131/911, Loss: 0.5135, Time: 2.95s\n",
      "Epoch: 13, Batch: 141/911, Loss: 0.5396, Time: 2.97s\n",
      "Epoch: 13, Batch: 151/911, Loss: 0.9179, Time: 2.94s\n",
      "Epoch: 13, Batch: 161/911, Loss: 0.4890, Time: 2.94s\n",
      "Epoch: 13, Batch: 171/911, Loss: 0.7880, Time: 2.96s\n",
      "Epoch: 13, Batch: 181/911, Loss: 0.5277, Time: 2.95s\n",
      "Epoch: 13, Batch: 191/911, Loss: 0.6885, Time: 2.95s\n",
      "Epoch: 13, Batch: 201/911, Loss: 0.7452, Time: 2.94s\n",
      "Epoch: 13, Batch: 211/911, Loss: 0.6202, Time: 2.94s\n",
      "Epoch: 13, Batch: 221/911, Loss: 0.6936, Time: 3.02s\n",
      "Epoch: 13, Batch: 231/911, Loss: 0.7236, Time: 3.04s\n",
      "Epoch: 13, Batch: 241/911, Loss: 0.6829, Time: 3.06s\n",
      "Epoch: 13, Batch: 251/911, Loss: 0.7296, Time: 2.96s\n",
      "Epoch: 13, Batch: 261/911, Loss: 0.7198, Time: 2.95s\n",
      "Epoch: 13, Batch: 271/911, Loss: 0.6566, Time: 2.96s\n",
      "Epoch: 13, Batch: 281/911, Loss: 0.7563, Time: 2.96s\n",
      "Epoch: 13, Batch: 291/911, Loss: 0.4660, Time: 2.94s\n",
      "Epoch: 13, Batch: 301/911, Loss: 0.5962, Time: 2.96s\n",
      "Epoch: 13, Batch: 311/911, Loss: 0.7372, Time: 2.95s\n",
      "Epoch: 13, Batch: 321/911, Loss: 0.6579, Time: 2.97s\n",
      "Epoch: 13, Batch: 331/911, Loss: 0.8964, Time: 2.95s\n",
      "Epoch: 13, Batch: 341/911, Loss: 0.7584, Time: 2.95s\n",
      "Epoch: 13, Batch: 351/911, Loss: 0.4091, Time: 2.98s\n",
      "Epoch: 13, Batch: 361/911, Loss: 0.5781, Time: 2.97s\n",
      "Epoch: 13, Batch: 371/911, Loss: 0.7129, Time: 2.96s\n",
      "Epoch: 13, Batch: 381/911, Loss: 0.6416, Time: 2.96s\n",
      "Epoch: 13, Batch: 391/911, Loss: 0.8403, Time: 2.94s\n",
      "Epoch: 13, Batch: 401/911, Loss: 0.5687, Time: 2.96s\n",
      "Epoch: 13, Batch: 411/911, Loss: 0.8645, Time: 2.94s\n",
      "Epoch: 13, Batch: 421/911, Loss: 0.6184, Time: 3.01s\n",
      "Epoch: 13, Batch: 431/911, Loss: 0.6774, Time: 3.05s\n",
      "Epoch: 13, Batch: 441/911, Loss: 0.8187, Time: 3.00s\n",
      "Epoch: 13, Batch: 451/911, Loss: 0.6514, Time: 2.96s\n",
      "Epoch: 13, Batch: 461/911, Loss: 0.9828, Time: 2.98s\n",
      "Epoch: 13, Batch: 471/911, Loss: 0.6996, Time: 2.95s\n",
      "Epoch: 13, Batch: 481/911, Loss: 0.5239, Time: 2.96s\n",
      "Epoch: 13, Batch: 491/911, Loss: 0.8585, Time: 2.97s\n",
      "Epoch: 13, Batch: 501/911, Loss: 0.7751, Time: 2.96s\n",
      "Epoch: 13, Batch: 511/911, Loss: 0.6193, Time: 2.95s\n",
      "Epoch: 13, Batch: 521/911, Loss: 0.4555, Time: 2.95s\n",
      "Epoch: 13, Batch: 531/911, Loss: 0.5909, Time: 2.96s\n",
      "Epoch: 13, Batch: 541/911, Loss: 0.8499, Time: 2.95s\n",
      "Epoch: 13, Batch: 551/911, Loss: 1.0591, Time: 2.95s\n",
      "Epoch: 13, Batch: 561/911, Loss: 0.7277, Time: 2.96s\n",
      "Epoch: 13, Batch: 571/911, Loss: 0.8246, Time: 2.96s\n",
      "Epoch: 13, Batch: 581/911, Loss: 0.6112, Time: 2.95s\n",
      "Epoch: 13, Batch: 591/911, Loss: 0.9375, Time: 3.00s\n",
      "Epoch: 13, Batch: 601/911, Loss: 0.5527, Time: 2.95s\n",
      "Epoch: 13, Batch: 611/911, Loss: 0.8074, Time: 2.95s\n",
      "Epoch: 13, Batch: 621/911, Loss: 0.5917, Time: 2.98s\n",
      "Epoch: 13, Batch: 631/911, Loss: 0.6986, Time: 3.04s\n",
      "Epoch: 13, Batch: 641/911, Loss: 0.7834, Time: 3.05s\n",
      "Epoch: 13, Batch: 651/911, Loss: 0.6246, Time: 2.97s\n",
      "Epoch: 13, Batch: 661/911, Loss: 0.7700, Time: 2.97s\n",
      "Epoch: 13, Batch: 671/911, Loss: 0.7032, Time: 2.96s\n",
      "Epoch: 13, Batch: 681/911, Loss: 0.6480, Time: 2.98s\n",
      "Epoch: 13, Batch: 691/911, Loss: 0.6548, Time: 2.96s\n",
      "Epoch: 13, Batch: 701/911, Loss: 0.8294, Time: 2.98s\n",
      "Epoch: 13, Batch: 711/911, Loss: 0.7257, Time: 2.95s\n",
      "Epoch: 13, Batch: 721/911, Loss: 0.8992, Time: 2.95s\n",
      "Epoch: 13, Batch: 731/911, Loss: 0.8977, Time: 2.96s\n",
      "Epoch: 13, Batch: 741/911, Loss: 0.7193, Time: 2.95s\n",
      "Epoch: 13, Batch: 751/911, Loss: 0.8000, Time: 2.94s\n",
      "Epoch: 13, Batch: 761/911, Loss: 1.0164, Time: 2.95s\n",
      "Epoch: 13, Batch: 771/911, Loss: 0.5402, Time: 2.94s\n",
      "Epoch: 13, Batch: 781/911, Loss: 0.8679, Time: 2.97s\n",
      "Epoch: 13, Batch: 791/911, Loss: 0.6859, Time: 2.96s\n",
      "Epoch: 13, Batch: 801/911, Loss: 0.8492, Time: 2.95s\n",
      "Epoch: 13, Batch: 811/911, Loss: 0.5618, Time: 2.95s\n",
      "Epoch: 13, Batch: 821/911, Loss: 0.6494, Time: 2.95s\n",
      "Epoch: 13, Batch: 831/911, Loss: 0.6599, Time: 3.07s\n",
      "Epoch: 13, Batch: 841/911, Loss: 0.7326, Time: 3.03s\n",
      "Epoch: 13, Batch: 851/911, Loss: 0.6496, Time: 2.96s\n",
      "Epoch: 13, Batch: 861/911, Loss: 0.7813, Time: 2.95s\n",
      "Epoch: 13, Batch: 871/911, Loss: 0.5985, Time: 2.95s\n",
      "Epoch: 13, Batch: 881/911, Loss: 0.7354, Time: 2.94s\n",
      "Epoch: 13, Batch: 891/911, Loss: 0.5981, Time: 2.94s\n",
      "Epoch: 13, Batch: 901/911, Loss: 0.6337, Time: 2.93s\n",
      "Epoch: 13, Batch: 911/911, Loss: 0.6049, Time: 2.94s\n",
      "Epoch 13/100: Train Loss: 0.6778, Val Loss: 0.7793, Val IoU: 0.2521, Val Dice: 0.3085\n",
      "Epoch: 14, Batch: 1/911, Loss: 0.5569, Time: 0.33s\n",
      "Epoch: 14, Batch: 11/911, Loss: 0.5433, Time: 2.97s\n",
      "Epoch: 14, Batch: 21/911, Loss: 0.8746, Time: 2.95s\n",
      "Epoch: 14, Batch: 31/911, Loss: 0.8676, Time: 2.95s\n",
      "Epoch: 14, Batch: 41/911, Loss: 0.5412, Time: 2.96s\n",
      "Epoch: 14, Batch: 51/911, Loss: 0.6524, Time: 2.96s\n",
      "Epoch: 14, Batch: 61/911, Loss: 0.8984, Time: 2.95s\n",
      "Epoch: 14, Batch: 71/911, Loss: 0.5069, Time: 3.02s\n",
      "Epoch: 14, Batch: 81/911, Loss: 0.6784, Time: 2.96s\n",
      "Epoch: 14, Batch: 91/911, Loss: 0.5363, Time: 2.97s\n",
      "Epoch: 14, Batch: 101/911, Loss: 0.5784, Time: 2.94s\n",
      "Epoch: 14, Batch: 111/911, Loss: 0.6933, Time: 2.96s\n",
      "Epoch: 14, Batch: 121/911, Loss: 0.6754, Time: 2.94s\n",
      "Epoch: 14, Batch: 131/911, Loss: 0.7405, Time: 2.96s\n",
      "Epoch: 14, Batch: 141/911, Loss: 0.7884, Time: 2.97s\n",
      "Epoch: 14, Batch: 151/911, Loss: 0.8036, Time: 3.03s\n",
      "Epoch: 14, Batch: 161/911, Loss: 0.6611, Time: 3.11s\n",
      "Epoch: 14, Batch: 171/911, Loss: 0.6025, Time: 3.00s\n",
      "Epoch: 14, Batch: 181/911, Loss: 0.7586, Time: 2.99s\n",
      "Epoch: 14, Batch: 191/911, Loss: 0.7972, Time: 2.96s\n",
      "Epoch: 14, Batch: 201/911, Loss: 0.7379, Time: 2.95s\n",
      "Epoch: 14, Batch: 211/911, Loss: 0.6933, Time: 2.98s\n",
      "Epoch: 14, Batch: 221/911, Loss: 0.6421, Time: 2.95s\n",
      "Epoch: 14, Batch: 231/911, Loss: 0.7579, Time: 2.96s\n",
      "Epoch: 14, Batch: 241/911, Loss: 0.7525, Time: 2.94s\n",
      "Epoch: 14, Batch: 251/911, Loss: 0.6323, Time: 2.96s\n",
      "Epoch: 14, Batch: 261/911, Loss: 0.6332, Time: 2.95s\n",
      "Epoch: 14, Batch: 271/911, Loss: 0.7695, Time: 2.96s\n",
      "Epoch: 14, Batch: 281/911, Loss: 0.5936, Time: 2.97s\n",
      "Epoch: 14, Batch: 291/911, Loss: 0.8059, Time: 2.95s\n",
      "Epoch: 14, Batch: 301/911, Loss: 0.7893, Time: 2.94s\n",
      "Epoch: 14, Batch: 311/911, Loss: 0.7445, Time: 2.95s\n",
      "Epoch: 14, Batch: 321/911, Loss: 0.8496, Time: 2.98s\n",
      "Epoch: 14, Batch: 331/911, Loss: 0.6905, Time: 2.94s\n",
      "Epoch: 14, Batch: 341/911, Loss: 0.6968, Time: 3.01s\n",
      "Epoch: 14, Batch: 351/911, Loss: 0.5093, Time: 3.04s\n",
      "Epoch: 14, Batch: 361/911, Loss: 0.6713, Time: 3.01s\n",
      "Epoch: 14, Batch: 371/911, Loss: 0.6519, Time: 3.02s\n",
      "Epoch: 14, Batch: 381/911, Loss: 0.7253, Time: 2.95s\n",
      "Epoch: 14, Batch: 391/911, Loss: 0.6180, Time: 2.99s\n",
      "Epoch: 14, Batch: 401/911, Loss: 0.7080, Time: 3.07s\n",
      "Epoch: 14, Batch: 411/911, Loss: 0.6467, Time: 3.06s\n",
      "Epoch: 14, Batch: 421/911, Loss: 0.7725, Time: 2.95s\n",
      "Epoch: 14, Batch: 431/911, Loss: 0.8000, Time: 2.95s\n",
      "Epoch: 14, Batch: 441/911, Loss: 0.6634, Time: 2.96s\n",
      "Epoch: 14, Batch: 451/911, Loss: 0.9357, Time: 2.97s\n",
      "Epoch: 14, Batch: 461/911, Loss: 0.5312, Time: 2.95s\n",
      "Epoch: 14, Batch: 471/911, Loss: 0.6670, Time: 2.96s\n",
      "Epoch: 14, Batch: 481/911, Loss: 0.5977, Time: 2.96s\n",
      "Epoch: 14, Batch: 491/911, Loss: 1.2020, Time: 2.97s\n",
      "Epoch: 14, Batch: 501/911, Loss: 0.6009, Time: 2.97s\n",
      "Epoch: 14, Batch: 511/911, Loss: 0.5377, Time: 2.96s\n",
      "Epoch: 14, Batch: 521/911, Loss: 0.8860, Time: 2.98s\n",
      "Epoch: 14, Batch: 531/911, Loss: 0.5218, Time: 2.98s\n",
      "Epoch: 14, Batch: 541/911, Loss: 0.5507, Time: 2.98s\n",
      "Epoch: 14, Batch: 551/911, Loss: 0.5839, Time: 3.05s\n",
      "Epoch: 14, Batch: 561/911, Loss: 0.7562, Time: 3.12s\n",
      "Epoch: 14, Batch: 571/911, Loss: 0.5531, Time: 3.07s\n",
      "Epoch: 14, Batch: 581/911, Loss: 0.5753, Time: 2.97s\n",
      "Epoch: 14, Batch: 591/911, Loss: 0.6088, Time: 2.96s\n",
      "Epoch: 14, Batch: 601/911, Loss: 0.8154, Time: 2.96s\n",
      "Epoch: 14, Batch: 611/911, Loss: 0.7381, Time: 2.97s\n",
      "Epoch: 14, Batch: 621/911, Loss: 0.6330, Time: 2.99s\n",
      "Epoch: 14, Batch: 631/911, Loss: 0.6040, Time: 2.95s\n",
      "Epoch: 14, Batch: 641/911, Loss: 0.7288, Time: 2.95s\n",
      "Epoch: 14, Batch: 651/911, Loss: 0.6431, Time: 2.96s\n",
      "Epoch: 14, Batch: 661/911, Loss: 0.8380, Time: 2.95s\n",
      "Epoch: 14, Batch: 671/911, Loss: 0.7589, Time: 2.96s\n",
      "Epoch: 14, Batch: 681/911, Loss: 0.5910, Time: 2.95s\n",
      "Epoch: 14, Batch: 691/911, Loss: 0.6804, Time: 2.97s\n",
      "Epoch: 14, Batch: 701/911, Loss: 0.8534, Time: 2.94s\n",
      "Epoch: 14, Batch: 711/911, Loss: 0.6020, Time: 2.97s\n",
      "Epoch: 14, Batch: 721/911, Loss: 0.7015, Time: 2.96s\n",
      "Epoch: 14, Batch: 731/911, Loss: 0.6991, Time: 2.95s\n",
      "Epoch: 14, Batch: 741/911, Loss: 0.6171, Time: 2.94s\n",
      "Epoch: 14, Batch: 751/911, Loss: 0.7154, Time: 3.03s\n",
      "Epoch: 14, Batch: 761/911, Loss: 0.6691, Time: 3.02s\n",
      "Epoch: 14, Batch: 771/911, Loss: 0.6287, Time: 3.05s\n",
      "Epoch: 14, Batch: 781/911, Loss: 0.6516, Time: 2.94s\n",
      "Epoch: 14, Batch: 791/911, Loss: 0.6131, Time: 2.95s\n",
      "Epoch: 14, Batch: 801/911, Loss: 0.6689, Time: 2.95s\n",
      "Epoch: 14, Batch: 811/911, Loss: 0.6186, Time: 2.96s\n",
      "Epoch: 14, Batch: 821/911, Loss: 0.6720, Time: 2.95s\n",
      "Epoch: 14, Batch: 831/911, Loss: 0.6449, Time: 2.95s\n",
      "Epoch: 14, Batch: 841/911, Loss: 0.7269, Time: 2.94s\n",
      "Epoch: 14, Batch: 851/911, Loss: 0.8576, Time: 2.95s\n",
      "Epoch: 14, Batch: 861/911, Loss: 0.5568, Time: 2.96s\n",
      "Epoch: 14, Batch: 871/911, Loss: 0.7653, Time: 2.93s\n",
      "Epoch: 14, Batch: 881/911, Loss: 0.7730, Time: 2.96s\n",
      "Epoch: 14, Batch: 891/911, Loss: 0.7542, Time: 2.95s\n",
      "Epoch: 14, Batch: 901/911, Loss: 0.7037, Time: 2.95s\n",
      "Epoch: 14, Batch: 911/911, Loss: 0.5299, Time: 2.94s\n",
      "Epoch 14/100: Train Loss: 0.6816, Val Loss: 0.7658, Val IoU: 0.2582, Val Dice: 0.3179\n",
      "Saving best model with IoU: 0.2582\n",
      "Epoch: 15, Batch: 1/911, Loss: 0.4376, Time: 0.33s\n",
      "Epoch: 15, Batch: 11/911, Loss: 0.4926, Time: 2.94s\n",
      "Epoch: 15, Batch: 21/911, Loss: 0.8230, Time: 2.95s\n",
      "Epoch: 15, Batch: 31/911, Loss: 0.6572, Time: 2.96s\n",
      "Epoch: 15, Batch: 41/911, Loss: 0.6672, Time: 2.95s\n",
      "Epoch: 15, Batch: 51/911, Loss: 0.8097, Time: 2.95s\n",
      "Epoch: 15, Batch: 61/911, Loss: 0.5935, Time: 2.95s\n",
      "Epoch: 15, Batch: 71/911, Loss: 0.8515, Time: 2.95s\n",
      "Epoch: 15, Batch: 81/911, Loss: 0.6388, Time: 3.03s\n",
      "Epoch: 15, Batch: 91/911, Loss: 0.6440, Time: 3.07s\n",
      "Epoch: 15, Batch: 101/911, Loss: 0.9768, Time: 2.97s\n",
      "Epoch: 15, Batch: 111/911, Loss: 0.7793, Time: 2.99s\n",
      "Epoch: 15, Batch: 121/911, Loss: 0.6382, Time: 2.95s\n",
      "Epoch: 15, Batch: 131/911, Loss: 0.6624, Time: 2.96s\n",
      "Epoch: 15, Batch: 141/911, Loss: 0.4173, Time: 2.96s\n",
      "Epoch: 15, Batch: 151/911, Loss: 0.8347, Time: 2.96s\n",
      "Epoch: 15, Batch: 161/911, Loss: 0.5083, Time: 2.96s\n",
      "Epoch: 15, Batch: 171/911, Loss: 0.6927, Time: 2.95s\n",
      "Epoch: 15, Batch: 181/911, Loss: 0.5547, Time: 2.97s\n",
      "Epoch: 15, Batch: 191/911, Loss: 0.6274, Time: 2.95s\n",
      "Epoch: 15, Batch: 201/911, Loss: 0.6259, Time: 2.95s\n",
      "Epoch: 15, Batch: 211/911, Loss: 0.6056, Time: 2.99s\n",
      "Epoch: 15, Batch: 221/911, Loss: 0.6414, Time: 2.93s\n",
      "Epoch: 15, Batch: 231/911, Loss: 0.4939, Time: 2.95s\n",
      "Epoch: 15, Batch: 241/911, Loss: 0.7568, Time: 2.94s\n",
      "Epoch: 15, Batch: 251/911, Loss: 0.6213, Time: 2.97s\n",
      "Epoch: 15, Batch: 261/911, Loss: 0.6980, Time: 2.98s\n",
      "Epoch: 15, Batch: 271/911, Loss: 0.6699, Time: 2.96s\n",
      "Epoch: 15, Batch: 281/911, Loss: 0.5916, Time: 3.02s\n",
      "Epoch: 15, Batch: 291/911, Loss: 0.7771, Time: 3.02s\n",
      "Epoch: 15, Batch: 301/911, Loss: 0.7516, Time: 3.05s\n",
      "Epoch: 15, Batch: 311/911, Loss: 0.6783, Time: 2.95s\n",
      "Epoch: 15, Batch: 321/911, Loss: 0.7662, Time: 2.98s\n",
      "Epoch: 15, Batch: 331/911, Loss: 0.6508, Time: 2.93s\n",
      "Epoch: 15, Batch: 341/911, Loss: 0.5580, Time: 2.96s\n",
      "Epoch: 15, Batch: 351/911, Loss: 0.6462, Time: 2.96s\n",
      "Epoch: 15, Batch: 361/911, Loss: 0.5529, Time: 2.96s\n",
      "Epoch: 15, Batch: 371/911, Loss: 0.7305, Time: 2.94s\n",
      "Epoch: 15, Batch: 381/911, Loss: 0.5865, Time: 2.96s\n",
      "Epoch: 15, Batch: 391/911, Loss: 0.5778, Time: 2.95s\n",
      "Epoch: 15, Batch: 401/911, Loss: 0.6825, Time: 2.94s\n",
      "Epoch: 15, Batch: 411/911, Loss: 0.5950, Time: 2.95s\n",
      "Epoch: 15, Batch: 421/911, Loss: 0.6573, Time: 2.94s\n",
      "Epoch: 15, Batch: 431/911, Loss: 0.6960, Time: 2.96s\n",
      "Epoch: 15, Batch: 441/911, Loss: 0.6827, Time: 2.94s\n",
      "Epoch: 15, Batch: 451/911, Loss: 0.7360, Time: 2.95s\n",
      "Epoch: 15, Batch: 461/911, Loss: 0.7280, Time: 2.95s\n",
      "Epoch: 15, Batch: 471/911, Loss: 0.4921, Time: 2.95s\n",
      "Epoch: 15, Batch: 481/911, Loss: 0.6556, Time: 2.99s\n",
      "Epoch: 15, Batch: 491/911, Loss: 0.6169, Time: 3.08s\n",
      "Epoch: 15, Batch: 501/911, Loss: 0.6938, Time: 3.05s\n",
      "Epoch: 15, Batch: 511/911, Loss: 0.7417, Time: 2.97s\n",
      "Epoch: 15, Batch: 521/911, Loss: 0.7459, Time: 2.95s\n",
      "Epoch: 15, Batch: 531/911, Loss: 0.6087, Time: 2.99s\n",
      "Epoch: 15, Batch: 541/911, Loss: 0.6570, Time: 2.96s\n",
      "Epoch: 15, Batch: 551/911, Loss: 0.6451, Time: 2.96s\n",
      "Epoch: 15, Batch: 561/911, Loss: 0.7247, Time: 2.97s\n",
      "Epoch: 15, Batch: 571/911, Loss: 0.9251, Time: 2.95s\n",
      "Epoch: 15, Batch: 581/911, Loss: 0.5443, Time: 2.96s\n",
      "Epoch: 15, Batch: 591/911, Loss: 0.6301, Time: 2.95s\n",
      "Epoch: 15, Batch: 601/911, Loss: 0.5856, Time: 2.95s\n",
      "Epoch: 15, Batch: 611/911, Loss: 0.6289, Time: 2.95s\n",
      "Epoch: 15, Batch: 621/911, Loss: 0.4857, Time: 2.95s\n",
      "Epoch: 15, Batch: 631/911, Loss: 0.6219, Time: 2.95s\n",
      "Epoch: 15, Batch: 641/911, Loss: 0.6160, Time: 2.98s\n",
      "Epoch: 15, Batch: 651/911, Loss: 0.6033, Time: 2.95s\n",
      "Epoch: 15, Batch: 661/911, Loss: 0.7908, Time: 2.96s\n",
      "Epoch: 15, Batch: 671/911, Loss: 0.6900, Time: 2.96s\n",
      "Epoch: 15, Batch: 681/911, Loss: 0.5841, Time: 3.01s\n",
      "Epoch: 15, Batch: 691/911, Loss: 0.6198, Time: 3.07s\n",
      "Epoch: 15, Batch: 701/911, Loss: 0.5724, Time: 3.03s\n",
      "Epoch: 15, Batch: 711/911, Loss: 0.6969, Time: 2.95s\n",
      "Epoch: 15, Batch: 721/911, Loss: 0.7894, Time: 2.95s\n",
      "Epoch: 15, Batch: 731/911, Loss: 0.4845, Time: 2.96s\n",
      "Epoch: 15, Batch: 741/911, Loss: 0.6043, Time: 2.96s\n",
      "Epoch: 15, Batch: 751/911, Loss: 0.4786, Time: 2.96s\n",
      "Epoch: 15, Batch: 761/911, Loss: 0.7072, Time: 2.95s\n",
      "Epoch: 15, Batch: 771/911, Loss: 0.5736, Time: 2.93s\n",
      "Epoch: 15, Batch: 781/911, Loss: 0.6923, Time: 2.97s\n",
      "Epoch: 15, Batch: 791/911, Loss: 0.7777, Time: 2.96s\n",
      "Epoch: 15, Batch: 801/911, Loss: 0.5321, Time: 2.95s\n",
      "Epoch: 15, Batch: 811/911, Loss: 0.6834, Time: 2.94s\n",
      "Epoch: 15, Batch: 821/911, Loss: 0.9421, Time: 2.94s\n",
      "Epoch: 15, Batch: 831/911, Loss: 0.7192, Time: 2.95s\n",
      "Epoch: 15, Batch: 841/911, Loss: 0.5615, Time: 2.96s\n",
      "Epoch: 15, Batch: 851/911, Loss: 0.6734, Time: 2.94s\n",
      "Epoch: 15, Batch: 861/911, Loss: 0.6702, Time: 2.94s\n",
      "Epoch: 15, Batch: 871/911, Loss: 0.7339, Time: 2.95s\n",
      "Epoch: 15, Batch: 881/911, Loss: 0.7047, Time: 2.94s\n",
      "Epoch: 15, Batch: 891/911, Loss: 0.6628, Time: 2.94s\n",
      "Epoch: 15, Batch: 901/911, Loss: 0.5642, Time: 2.99s\n",
      "Epoch: 15, Batch: 911/911, Loss: 0.6435, Time: 2.97s\n",
      "Epoch 15/100: Train Loss: 0.6559, Val Loss: 0.6817, Val IoU: 0.2731, Val Dice: 0.3312\n",
      "Saving best model with IoU: 0.2731\n",
      "Epoch: 16, Batch: 1/911, Loss: 0.5484, Time: 0.34s\n",
      "Epoch: 16, Batch: 11/911, Loss: 0.7210, Time: 3.09s\n",
      "Epoch: 16, Batch: 21/911, Loss: 0.5610, Time: 3.03s\n",
      "Epoch: 16, Batch: 31/911, Loss: 0.7805, Time: 2.99s\n",
      "Epoch: 16, Batch: 41/911, Loss: 0.6051, Time: 2.95s\n",
      "Epoch: 16, Batch: 51/911, Loss: 0.5329, Time: 2.93s\n",
      "Epoch: 16, Batch: 61/911, Loss: 0.7082, Time: 2.94s\n",
      "Epoch: 16, Batch: 71/911, Loss: 0.6641, Time: 2.97s\n",
      "Epoch: 16, Batch: 81/911, Loss: 0.8707, Time: 2.95s\n",
      "Epoch: 16, Batch: 91/911, Loss: 0.6695, Time: 2.94s\n",
      "Epoch: 16, Batch: 101/911, Loss: 0.7464, Time: 2.95s\n",
      "Epoch: 16, Batch: 111/911, Loss: 0.7079, Time: 2.95s\n",
      "Epoch: 16, Batch: 121/911, Loss: 0.6832, Time: 2.96s\n",
      "Epoch: 16, Batch: 131/911, Loss: 0.5855, Time: 2.95s\n",
      "Epoch: 16, Batch: 141/911, Loss: 0.5540, Time: 2.95s\n",
      "Epoch: 16, Batch: 151/911, Loss: 0.5360, Time: 2.97s\n",
      "Epoch: 16, Batch: 161/911, Loss: 0.5755, Time: 2.94s\n",
      "Epoch: 16, Batch: 171/911, Loss: 0.7527, Time: 2.96s\n",
      "Epoch: 16, Batch: 181/911, Loss: 0.6807, Time: 2.95s\n",
      "Epoch: 16, Batch: 191/911, Loss: 0.5501, Time: 2.95s\n",
      "Epoch: 16, Batch: 201/911, Loss: 0.6071, Time: 2.95s\n",
      "Epoch: 16, Batch: 211/911, Loss: 0.6286, Time: 3.06s\n",
      "Epoch: 16, Batch: 221/911, Loss: 0.4669, Time: 3.09s\n",
      "Epoch: 16, Batch: 231/911, Loss: 0.4712, Time: 2.99s\n",
      "Epoch: 16, Batch: 241/911, Loss: 0.8577, Time: 2.94s\n",
      "Epoch: 16, Batch: 251/911, Loss: 0.6045, Time: 2.98s\n",
      "Epoch: 16, Batch: 261/911, Loss: 0.6406, Time: 2.97s\n",
      "Epoch: 16, Batch: 271/911, Loss: 0.6051, Time: 2.95s\n",
      "Epoch: 16, Batch: 281/911, Loss: 0.5154, Time: 2.96s\n",
      "Epoch: 16, Batch: 291/911, Loss: 0.6546, Time: 2.93s\n",
      "Epoch: 16, Batch: 301/911, Loss: 0.6197, Time: 2.95s\n",
      "Epoch: 16, Batch: 311/911, Loss: 0.6138, Time: 2.97s\n",
      "Epoch: 16, Batch: 321/911, Loss: 0.7306, Time: 2.95s\n",
      "Epoch: 16, Batch: 331/911, Loss: 0.5179, Time: 2.93s\n",
      "Epoch: 16, Batch: 341/911, Loss: 0.7711, Time: 2.96s\n",
      "Epoch: 16, Batch: 351/911, Loss: 0.6027, Time: 2.95s\n",
      "Epoch: 16, Batch: 361/911, Loss: 0.6406, Time: 2.97s\n",
      "Epoch: 16, Batch: 371/911, Loss: 0.6481, Time: 2.94s\n",
      "Epoch: 16, Batch: 381/911, Loss: 0.6588, Time: 2.95s\n",
      "Epoch: 16, Batch: 391/911, Loss: 0.7014, Time: 2.95s\n",
      "Epoch: 16, Batch: 401/911, Loss: 0.7230, Time: 2.95s\n",
      "Epoch: 16, Batch: 411/911, Loss: 0.7037, Time: 3.05s\n",
      "Epoch: 16, Batch: 421/911, Loss: 0.6591, Time: 3.02s\n",
      "Epoch: 16, Batch: 431/911, Loss: 0.5799, Time: 3.04s\n",
      "Epoch: 16, Batch: 441/911, Loss: 0.6448, Time: 2.95s\n",
      "Epoch: 16, Batch: 451/911, Loss: 0.6240, Time: 2.96s\n",
      "Epoch: 16, Batch: 461/911, Loss: 0.6369, Time: 2.94s\n",
      "Epoch: 16, Batch: 471/911, Loss: 0.5759, Time: 2.97s\n",
      "Epoch: 16, Batch: 481/911, Loss: 0.6407, Time: 2.94s\n",
      "Epoch: 16, Batch: 491/911, Loss: 0.4970, Time: 2.96s\n",
      "Epoch: 16, Batch: 501/911, Loss: 1.2436, Time: 2.96s\n",
      "Epoch: 16, Batch: 511/911, Loss: 0.7909, Time: 2.96s\n",
      "Epoch: 16, Batch: 521/911, Loss: 0.5324, Time: 2.94s\n",
      "Epoch: 16, Batch: 531/911, Loss: 0.4445, Time: 2.95s\n",
      "Epoch: 16, Batch: 541/911, Loss: 0.7181, Time: 2.95s\n",
      "Epoch: 16, Batch: 551/911, Loss: 0.5633, Time: 2.94s\n",
      "Epoch: 16, Batch: 561/911, Loss: 0.5720, Time: 2.94s\n",
      "Epoch: 16, Batch: 571/911, Loss: 0.5683, Time: 2.99s\n",
      "Epoch: 16, Batch: 581/911, Loss: 0.4708, Time: 2.95s\n",
      "Epoch: 16, Batch: 591/911, Loss: 0.5855, Time: 2.96s\n",
      "Epoch: 16, Batch: 601/911, Loss: 0.6604, Time: 2.96s\n",
      "Epoch: 16, Batch: 611/911, Loss: 0.7199, Time: 3.00s\n",
      "Epoch: 16, Batch: 621/911, Loss: 0.5635, Time: 3.10s\n",
      "Epoch: 16, Batch: 631/911, Loss: 0.7062, Time: 3.04s\n",
      "Epoch: 16, Batch: 641/911, Loss: 0.6083, Time: 2.95s\n",
      "Epoch: 16, Batch: 651/911, Loss: 0.6849, Time: 2.96s\n",
      "Epoch: 16, Batch: 661/911, Loss: 0.9659, Time: 2.95s\n"
     ]
    }
   ],
   "source": [
    "geoai.train_segmentation_model(\n",
    "    images_dir=f\"{data_folder}/images\",\n",
    "    labels_dir=f\"{data_folder}/labels\",\n",
    "    output_dir=f\"{model_folder}/deeplabv3plus_efb4_models\",\n",
    "    architecture=\"deeplabv3plus\",\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=None,\n",
    "    num_channels=9,\n",
    "    num_classes=11, # background and 10 crop classes\n",
    "    batch_size=8,\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.0005,\n",
    "    val_split=0.2,\n",
    "    # criterion=criterion,\n",
    "    verbose=True,\n",
    "    class_balanced=True,\n",
    "    save_best_only=False,\n",
    "    checkpoint_interval=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804befb",
   "metadata": {},
   "source": [
    "#### Plot model perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.plot_performance_metrics(\n",
    "    history_path=f\"{model_folder}/deeplabv3plus_efb4_models/training_history.pth\",\n",
    "    figsize=(15, 5),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a13dcd",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932198f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file format: GeoTIFF (.tif)\n",
      "Processing 1102 windows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1170it [00:16, 70.30it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: 11 classes, Background: 47.4%\n",
      "Inference completed in 26.37 seconds\n",
      "Saved prediction to ../data/predicted/crop_mapping_2023_07_30/S2H_2024_2024_07_29_pred.tif\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "model_path = f\"{model_folder}/deeplabv3plus_efb4_models/best_model.pth\"\n",
    "test_raster_path = \"../data/raw/images/S2H_2024_2024_07_29_nodata.tif\"\n",
    "predicted_path = f\"../data/predicted/{out_name}/S2H_2024_2024_07_29_pred.tif\"\n",
    "\n",
    "# Run semantic segmentation inference\n",
    "geoai.semantic_segmentation(\n",
    "    input_path=test_raster_path,\n",
    "    output_path=predicted_path,\n",
    "    model_path=model_path,\n",
    "    architecture=\"deeplabv3plus\",\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    num_channels=9,\n",
    "    num_classes=11,\n",
    "    window_size=256,\n",
    "    overlap=64,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b072f87",
   "metadata": {},
   "source": [
    "#### Remap class pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique compact values in prediction: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Saved restored raster to ../data/predicted/crop_mapping_2023_07_30/S2H_2024_2024_07_29_pred_remap.tif\n",
      "Unique values: [  0   1   3  24  36  54  69  75  76 210 211]\n"
     ]
    }
   ],
   "source": [
    "from geoai import label_utils\n",
    "\n",
    "# Map them into compact range\n",
    "mapping = {\n",
    "    0: 0,   # Background\n",
    "    1: 1,   # Corn\n",
    "    3: 2,   # Rice\n",
    "    24: 3,  # Winter Wheat\n",
    "    36: 4,  # Alfalfa\n",
    "    54: 5,  # Tomatoes\n",
    "    69: 6,  # Grapes\n",
    "    75: 7,  # Almonds\n",
    "    76: 8,  # Walnuts\n",
    "    210: 9, # Prunes\n",
    "    211: 10 # Olives\n",
    "}\n",
    "\n",
    "# Remap back to original class codes\n",
    "label_utils.remap_back_raster(\n",
    "    in_path=predicted_path,\n",
    "    out_path=predicted_path.replace(\".tif\", \"_remap.tif\"),\n",
    "    mapping=mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1001d2",
   "metadata": {},
   "source": [
    "#### Visualize pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acfc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a12686ff2bb41e2bc546e1cd351de7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38.929975, -121.751141], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.constants import USDA_CDL_COLORS\n",
    "\n",
    "geoai.view_raster_with_labels(\n",
    "    raster_image=test_raster_path,\n",
    "    label_raster=predicted_path,\n",
    "    class_mapping={\n",
    "        0: \"Background\",\n",
    "        1: \"Corn\",\n",
    "        3: \"Rice\",\n",
    "        24: \"Winter Wheat\",\n",
    "        36: \"Alfalfa\",\n",
    "        54: \"Tomatoes\",\n",
    "        69: \"Grapes\",\n",
    "        75: \"Almonds\",\n",
    "        76: \"Walnuts\",\n",
    "        210: \"Prunes\",\n",
    "        211: \"Olives\"\n",
    "    },\n",
    "    class_colors={\n",
    "        0: USDA_CDL_COLORS.get(0),\n",
    "        1: USDA_CDL_COLORS.get(1),\n",
    "        3: USDA_CDL_COLORS.get(3),\n",
    "        24: USDA_CDL_COLORS.get(24),\n",
    "        36: USDA_CDL_COLORS.get(36),\n",
    "        54: USDA_CDL_COLORS.get(54),\n",
    "        69: USDA_CDL_COLORS.get(69),\n",
    "        75: USDA_CDL_COLORS.get(75),\n",
    "        76: USDA_CDL_COLORS.get(76),\n",
    "        210: USDA_CDL_COLORS.get(210),\n",
    "        211: USDA_CDL_COLORS.get(211)\n",
    "    },\n",
    "    raster_indexes=(3, 2, 1),\n",
    "    raster_layer_name=\"Satellite\",\n",
    "    label_layer_name=\"Labels\",\n",
    "    legend_title=\"Crop Classes\",\n",
    "    opacity=0.5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_crop_mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
